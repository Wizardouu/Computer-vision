{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":89993,"databundleVersionId":10699058,"isSourceIdPinned":false,"sourceType":"competition"},{"sourceId":4958499,"sourceType":"datasetVersion","datasetId":2875539}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# YOLO Finetuning","metadata":{"_uuid":"ef26a966-bd95-40c6-8f77-f411e4d0a9a5","_cell_guid":"3db2dd0a-8276-4b99-af44-06903ed0ebf9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"!pip -q install ultralytics","metadata":{"_uuid":"bf9c13e0-9283-459f-b52a-b95950b432a9","_cell_guid":"9bb1ab1d-c0bc-465a-8b8d-36bbeaf7a1f0","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\n\ndataset_path = \"/kaggle/input/surveillance-for-retail-stores/tracking\"\noutput_labels = \"/kaggle/working/labels\"\nos.makedirs(output_labels, exist_ok=True)\n\nsequences = [\"02\", \"03\", \"05\"]  # Training sequences\n\nfor seq in sequences:\n    gt_file = os.path.join(dataset_path, \"train\", seq, \"gt/gt.txt\")\n    img_dir = os.path.join(dataset_path, \"train\", seq, \"img1\")\n    label_dir = os.path.join(output_labels, seq)\n    os.makedirs(label_dir, exist_ok=True)\n\n    with open(gt_file, \"r\") as f:\n        for line in f:\n            parts = line.strip().split(\",\")\n            frame, obj_id, x, y, w, h, conf, cls, visibility = map(float, parts)\n\n            img_width, img_height = 1920, 1080  # Adjust from seqinfo.ini\n            x_center = (x + w / 2) / img_width\n            y_center = (y + h / 2) / img_height\n            w /= img_width\n            h /= img_height\n\n            label_file = os.path.join(label_dir, f\"{int(frame):06d}.txt\")\n            with open(label_file, \"a\") as lf:\n                lf.write(f\"0 {x_center} {y_center} {w} {h}\\n\")","metadata":{"_uuid":"a5b166a5-fcf5-4b18-893a-560c4cc8483f","_cell_guid":"aced3815-945f-45f4-8652-d9cf15e5ebff","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport shutil\nfrom tqdm import tqdm\n\n# Define source image directories (read-only)\nimage_dirs = [\n    \"/kaggle/input/surveillance-for-retail-stores/tracking/train/02/img1\",\n    \"/kaggle/input/surveillance-for-retail-stores/tracking/train/03/img1\",\n    \"/kaggle/input/surveillance-for-retail-stores/tracking/train/05/img1\"\n]\nlabel_dirs = [\n    \"/kaggle/working/labels/02\",\n    \"/kaggle/working/labels/03\",\n    \"/kaggle/working/labels/05\"\n]\n\n# Define destination paths in /kaggle/working/\nworking_dir = \"/kaggle/working/dataset\"\nos.makedirs(working_dir, exist_ok=True)\n\nfor idx, img_dir in enumerate(image_dirs):\n    new_img_dir = os.path.join(working_dir, f\"train/{idx}/images\")\n    new_label_dir = os.path.join(working_dir, f\"train/{idx}/labels\")\n\n    os.makedirs(new_img_dir, exist_ok=True)\n    os.makedirs(new_label_dir, exist_ok=True)\n\n    # Copy images\n    for img_file in tqdm(os.listdir(img_dir), desc=f\"Copying images from {img_dir}\"):\n        src_path = os.path.join(img_dir, img_file)\n        dst_path = os.path.join(new_img_dir, img_file)\n        if os.path.isfile(src_path):\n            shutil.copy2(src_path, dst_path)\n\n    # Move corresponding labels\n    for lbl_file in tqdm(os.listdir(label_dirs[idx]), desc=f\"Moving labels for {img_dir}\"):\n        src_path = os.path.join(label_dirs[idx], lbl_file)\n        dst_path = os.path.join(new_label_dir, lbl_file)\n        if os.path.isfile(src_path):\n            shutil.move(src_path, dst_path)\n\nprint(\"Dataset restructuring complete!\")","metadata":{"_uuid":"4e845a27-2aaf-4a60-a3c8-bc13b959458b","_cell_guid":"259c5321-eb35-47c5-ac94-95f39646c309","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"yaml_content = \"\"\"train: \n- /kaggle/working/dataset/train/0\n- /kaggle/working/dataset/train/1\nval: /kaggle/working/dataset/train/2\n\nnc: 1\nnames: [\"person\"]\n\"\"\"\n\n# Save to a file\nyaml_path = \"/kaggle/working/dataset.yaml\"\nwith open(yaml_path, \"w\") as f:\n    f.write(yaml_content)\n\nprint(f\"dataset.yaml created at {yaml_path}\")","metadata":{"_uuid":"f6162679-f382-4771-a4b8-e37d97899fb3","_cell_guid":"9c2a181e-a2bf-413a-b308-f05693045ba6","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from ultralytics import YOLO\n\nmodel = YOLO(\"yolov8n.pt\")  # Use a small, non-MOT model\nmodel.train(data=\"/kaggle/working/dataset.yaml\", epochs=5, imgsz=640, batch=16, device=\"cuda\")","metadata":{"_uuid":"3b14ad37-b10e-4169-bd14-9d83ec6173eb","_cell_guid":"7f95caa3-88bc-4bcd-8f21-59dc4c971b4c","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false},"_kg_hide-output":false},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#model = YOLO(\"/kaggle/working/runs/detect/train/weights/best.pt\")\n#results = model.predict(source=\"/kaggle/input/surveillance-for-retail-stores/tracking/test/01/img1\", save=True, conf=0.4)","metadata":{"_uuid":"08e9868f-c0e7-478a-901a-b67f1757929c","_cell_guid":"3254381b-6783-4aaf-9c77-603f8297df62","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# ReID","metadata":{"_uuid":"22c47be6-603e-4a25-a7ab-bfc50fd83701","_cell_guid":"3c06ea40-270a-4ca6-aaa9-6fa6a72275c1","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"!pip -q install torchreid","metadata":{"_uuid":"33e3cfe2-cc61-4980-acd8-878cddac8ecc","_cell_guid":"d0edba7c-9840-4f48-b044-9d835ba60f68","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchreid\ntorchreid.models.show_avai_models()  # Check available models","metadata":{"_uuid":"77e4c9bd-ba42-45a7-a150-2f85eae11da7","_cell_guid":"edaf50b4-d55c-42af-93f0-72419b7a4fff","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"datamanager = torchreid.data.ImageDataManager(\n    root=\"/kaggle/input\",\n    sources=\"market1501\",\n    targets=\"market1501\",\n    height=256, width=128,\n    batch_size_train=32,\n    batch_size_test=32,\n    transforms=[\"random_flip\", \"random_crop\"],\n    use_gpu=True\n)","metadata":{"_uuid":"15657821-4b89-481e-8157-4c40eba99710","_cell_guid":"c0e4e990-b3bb-429c-84dc-efbfcea915fe","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = torchreid.models.build_model(\n    name=\"osnet_x1_0\",  \n    num_classes=datamanager.num_train_pids,  \n    pretrained=True\n)\nmodel = model.cuda()","metadata":{"_uuid":"2031a1d1-2bcc-481a-adfe-224e54f3209d","_cell_guid":"42a97328-9997-4078-a6e9-15233f83b2a8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"optimizer = torchreid.optim.build_optimizer(model, optim=\"adam\", lr=0.0005)\nscheduler = torchreid.optim.build_lr_scheduler(optimizer)\n\nengine = torchreid.engine.ImageSoftmaxEngine(\n    datamanager, model, optimizer, scheduler\n)\n\nengine.run(max_epoch=20, save_dir=\"log/osnet\", print_freq=1)","metadata":{"_uuid":"fb099f2c-6a14-46a1-9aa9-69ae118818a6","_cell_guid":"f4b21e8c-eacc-4c65-bdf4-6b92e757e330","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Merging","metadata":{"_uuid":"5a04edf7-3b45-405f-853b-f4ab13489468","_cell_guid":"999f0760-fc3b-4234-bead-f94e8249bf6f","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"from ultralytics import YOLO\nimport torch\nimport cv2\nimport numpy as np\n\ndetector = YOLO(\"/kaggle/working/runs/detect/train/weights/best.pt\")  \n\ndef detect_pedestrians(frame):\n    results = detector(frame)\n    detections = []\n    \n    for r in results:\n        for box in r.boxes.xywh.cpu().numpy():\n            x, y, w, h = box\n            detections.append([x, y, w, h, 1.0])  # Confidence = 1.0 for tracking\n    \n    return np.array(detections) if len(detections) > 0 else np.empty((0, 5))","metadata":{"_uuid":"2d7eef9e-95ff-4b71-89cc-0d87bd447626","_cell_guid":"45ab3c18-1f22-478a-be83-8d9a818232f8","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torchreid\nprint(torchreid.__file__)","metadata":{"_uuid":"8537c1cc-0830-4b8b-b080-5e84ce408037","_cell_guid":"33c2b74a-b7e7-4904-a062-0febf6476085","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pkgutil\nimport torchreid\n\nmodules = [module.name for module in pkgutil.iter_modules(torchreid.__path__)]\nprint(modules)","metadata":{"_uuid":"783f5d05-0b61-4396-a25c-81792f37819e","_cell_guid":"5c37964c-97ef-401e-b086-a2e80dabf066","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from torchreid.reid.utils import FeatureExtractor","metadata":{"_uuid":"dc755645-28d4-482d-88e4-45f62b8e19b1","_cell_guid":"42b74e06-9001-4716-b79e-4ab03e40d77d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\n# Load OSNet for embedding extraction\nextractor = FeatureExtractor(\n    model_name='osnet_x1_0',\n    model_path=\"/kaggle/working/log/osnet/model.pth.tar-20\",\n    device='cuda'\n)\n\n# Extract embeddings\ndef get_embedding(frame, bbox):\n    x, y, w, h = bbox\n    cropped = frame[int(y):int(y+h), int(x):int(x+w)]\n    cropped = cv2.resize(cropped, (128, 256))  # Resize for OSNet\n    embedding = extractor(cropped).cpu().detach().numpy()\n    return embedding","metadata":{"_uuid":"1d9a0ad7-3e67-4565-b432-fe73bc6653a0","_cell_guid":"82be5565-c82f-480a-99b1-1578180b12f2","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!git clone https://github.com/noahcao/OC_SORT.git","metadata":{"_uuid":"b82a01ae-d3d7-45eb-8695-802058daa850","_cell_guid":"cad8eb68-8c56-4608-90e9-17b6de357c70","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%cd OC_SORT\n!pip -q install -r requirements.txt","metadata":{"_uuid":"2cf0041f-4947-4c6b-be39-4aac2f4fa1fd","_cell_guid":"6bf78ae5-069e-44e4-ac29-2df8b77a827d","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip -q install filterpy","metadata":{"_uuid":"a5661a1c-fee3-4562-b35a-dc23d71153c8","_cell_guid":"3e4a927f-40b4-48ed-8e2c-f89f6f8745c9","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/working/OC_SORT\")","metadata":{"_uuid":"0599c067-4ef6-49be-af23-4f8d14fe8754","_cell_guid":"326eca9d-6834-48f3-9c8b-e0fbe4d7a7db","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"'''from trackers.ocsort_tracker.ocsort import OCSort\n\ntracker = OCSort(det_thresh=0.3, max_age=30, min_hits=3, iou_threshold=0.2)\n\ndef track_objects(frame, detections):\n    img_size = frame.shape[:2]  # (height, width)\n    img_info = (img_size[0], img_size[1], frame_id)  # Add frame_id as additional info if needed\n\n    tracked_objects = tracker.update(detections, img_info, img_size)\n    results = []\n\n    for obj in tracked_objects:\n        obj_id = int(obj[4])  # Assuming obj[4] contains the ID\n        bbox = obj[:4]  # Bounding box (x1, y1, x2, y2)\n        results.append({\"id\": obj_id, \"bbox\": bbox})\n\n    return results\n'''\nfrom trackers.ocsort_tracker.ocsort import OCSort\n\n# Initialize the tracker\ntracker = OCSort(det_thresh=0.25, max_age=100, min_hits=0, iou_threshold=0.2)\n\ndef track_objects(frame, detections):\n    img_size = frame.shape[:2]  # (height, width)\n    img_info = (img_size[0], img_size[1], frame_id)  # Add frame_id as additional info if needed\n\n    # Update tracker with new detections\n    tracked_objects = tracker.update(detections, img_info, img_size)\n    results = []\n\n    for obj in tracked_objects:\n        obj_id = int(obj[4])  # Assuming obj[4] contains the ID\n        bbox = obj[:4]  # Bounding box (x1, y1, x2, y2)\n        results.append({\"id\": obj_id, \"bbox\": bbox})\n\n    return results","metadata":{"_uuid":"56d39f5e-950d-4eeb-ae33-d169f7212fa7","_cell_guid":"a4c38a41-38ca-42e1-91aa-67b3d4dd53a4","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Inference","metadata":{"_uuid":"2e253f99-9171-459f-97b1-ecd4fc328a4a","_cell_guid":"2421aa72-0177-46de-b186-87ecf43ef4bb","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import csv\nimport os\nimport cv2\n\noutput_csv = \"/kaggle/working/submission_file_tracking.csv\"\n\nwith open(output_csv, \"w\", newline=\"\") as f:\n    writer = csv.writer(f)\n    writer.writerow([\"ID\", \"frame\", \"objects\", \"objective\"])\n\n    frame_id = 1  # Start frame numbering from 1\n    for seq in [\"01\"]:\n        img_dir = f\"/kaggle/input/surveillance-for-retail-stores/tracking/test/{seq}/img1\" \n        img_files = sorted(os.listdir(img_dir))\n        \n        for img_file in img_files:\n            img_path = os.path.join(img_dir, img_file)\n            frame = cv2.imread(img_path)\n\n            if frame is None:\n                print(f\"Warning: Failed to read {img_path}\")\n                continue  # Skip corrupted images\n\n            # Detect pedestrians in the current frame\n            detections = detect_pedestrians(frame)\n\n            # Track objects across frames\n            tracked_objects = track_objects(frame, detections)\n\n            # Format tracked objects for CSV\n            formatted_objects = []\n            for obj in tracked_objects:\n                obj_id = obj[\"id\"]  # Unique ID for each object\n                x1, y1, x2, y2 = obj[\"bbox\"]\n                w, h = x2 - x1, y2 - y1\n                confidence = 1.0  # Default confidence\n\n                formatted_objects.append({\n                    \"tracked_id\": obj_id,\n                    \"x\": int(x1),\n                    \"y\": int(y1),\n                    \"w\": int(w),\n                    \"h\": int(h),\n                    \"confidence\": round(float(confidence), 6)\n                })\n\n            # Write to CSV\n            writer.writerow([frame_id - 1, float(frame_id), str(formatted_objects), \"tracking\"])\n            print(f\"Frame {frame_id}: Num Tracked objects: {len(formatted_objects)}\")\n            frame_id += 1\n\nprint(\"Submission file done\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Face ReID","metadata":{}},{"cell_type":"code","source":"!pip -q install facenet-pytorch torchvision scipy pandas","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport json\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom PIL import Image\nimport torchvision.transforms as transforms\nfrom scipy.spatial.distance import cosine","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:05:07.377790Z","iopub.execute_input":"2025-03-23T22:05:07.378130Z","iopub.status.idle":"2025-03-23T22:05:10.013648Z","shell.execute_reply.started":"2025-03-23T22:05:07.378100Z","shell.execute_reply":"2025-03-23T22:05:10.012704Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"ROOT_DIR = \"/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification\"\n\n# Load train.csv\ndf_train = pd.read_csv(os.path.join(ROOT_DIR, \"trainset.csv\"))\n\n# Dictionary to store all image paths per person\ntrain_images = {}\n\nfor _, row in df_train.iterrows():\n    person = row[\"gt\"]  # Person ID\n    image_path = os.path.join(ROOT_DIR, row[\"image_path\"])  # Full image path\n\n    if os.path.exists(image_path):  # Check if file exists\n        if person not in train_images:\n            train_images[person] = []\n        train_images[person].append(image_path)  # Append image path to person's list\n    else:\n        print(f\"Image file does not exist: {image_path}\")  # Debugging\n\nprint(f\"Updated image paths for {len(train_images)} persons.\")\n\n# Check the first few entries\nfor person, img_paths in list(train_images.items())[:5]:\n    print(f\"{person}: {img_paths[:3]}\")  # Show only the first 3 images per person\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:56:15.997352Z","iopub.execute_input":"2025-03-23T21:56:15.997698Z","iopub.status.idle":"2025-03-23T21:56:27.493349Z","shell.execute_reply.started":"2025-03-23T21:56:15.997669Z","shell.execute_reply":"2025-03-23T21:56:27.492509Z"}},"outputs":[{"name":"stdout","text":"Updated image paths for 125 persons.\nperson_0: ['/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_0/0.jpg', '/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_0/1.jpg', '/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_0/10.jpg']\nperson_1: ['/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_1/23.jpg', '/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_1/24.jpg', '/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_1/25.jpg']\nperson_10: ['/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_10/67.jpg', '/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_10/68.jpg', '/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_10/71.jpg']\nperson_100: ['/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_100/100.jpg', '/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_100/101.jpg', '/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_100/102.jpg']\nperson_101: ['/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_101/184.jpg', '/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_101/185.jpg', '/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_101/186.jpg']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"pip install insightface onnxruntime-gpu numpy opencv-python","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:56:53.976384Z","iopub.execute_input":"2025-03-23T21:56:53.976708Z","iopub.status.idle":"2025-03-23T21:57:28.206063Z","shell.execute_reply.started":"2025-03-23T21:56:53.976672Z","shell.execute_reply":"2025-03-23T21:57:28.205122Z"}},"outputs":[{"name":"stdout","text":"Collecting insightface\n  Downloading insightface-0.7.3.tar.gz (439 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nCollecting onnxruntime-gpu\n  Downloading onnxruntime_gpu-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.8 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\nRequirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\nRequirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (from insightface) (1.17.0)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from insightface) (4.67.1)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from insightface) (2.32.3)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from insightface) (3.7.5)\nRequirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from insightface) (11.0.0)\nRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from insightface) (1.13.1)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from insightface) (1.2.2)\nRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from insightface) (0.25.0)\nRequirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from insightface) (1.13)\nRequirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from insightface) (3.0.11)\nRequirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from insightface) (1.4.20)\nRequirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from insightface) (3.12.0)\nCollecting coloredlogs (from onnxruntime-gpu)\n  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\nRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.3.25)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (24.2)\nRequirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (3.20.3)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime-gpu) (1.13.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (6.0.2)\nRequirement already satisfied: pydantic>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (2.11.0a2)\nRequirement already satisfied: albucore==0.0.19 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (0.0.19)\nRequirement already satisfied: eval-type-backport in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (0.2.0)\nRequirement already satisfied: opencv-python-headless>=4.9.0.80 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (4.10.0.84)\nRequirement already satisfied: stringzilla>=3.10.4 in /usr/local/lib/python3.10/dist-packages (from albucore==0.0.19->albumentations->insightface) (3.11.1)\nCollecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-gpu)\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (4.55.3)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.4.7)\nRequirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (3.2.0)\nRequirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (2.9.0.post0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->insightface) (0.2.13)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (2025.1.31)\nRequirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (3.4.2)\nRequirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2.36.1)\nRequirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2024.12.12)\nRequirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (0.4)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface) (3.5.0)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime-gpu) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (0.7.0)\nRequirement already satisfied: pydantic-core==2.29.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (2.29.0)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.7.0->albumentations->insightface) (4.12.2)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.17.0)\nDownloading onnxruntime_gpu-1.21.0-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (280.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.8/280.8 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: insightface\n  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for insightface: filename=insightface-0.7.3-cp310-cp310-linux_x86_64.whl size=1055450 sha256=2c3763a619d118a9483c13f3f2eb2380e436db1b4d2ca55c07d66bc1d282b6d9\n  Stored in directory: /root/.cache/pip/wheels/e3/d0/80/e3773fb8b6d1cca87ea1d33d9b1f20a223a6493c896da249b5\nSuccessfully built insightface\nInstalling collected packages: humanfriendly, coloredlogs, onnxruntime-gpu, insightface\nSuccessfully installed coloredlogs-15.0.1 humanfriendly-10.0 insightface-0.7.3 onnxruntime-gpu-1.21.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"import torch\nimport cv2\nimport numpy as np\nfrom insightface.app import FaceAnalysis\n\n# Check if CUDA is available\nuse_gpu = torch.cuda.is_available()\nproviders = ['CUDAExecutionProvider'] if use_gpu else ['CPUExecutionProvider']\n\nprint(f\"Using {'GPU' if use_gpu else 'CPU'}\")\n\n# Initialize ArcFace model\napp = FaceAnalysis(providers=providers)\napp.prepare(ctx_id=0 if use_gpu else -1, det_size=(160, 160))  # Ensure correct context ID\n\ndef get_embedding(image_path):\n    try:\n        # Load image\n        img = cv2.imread(image_path)\n        if img is None:\n            raise ValueError(\"Image not found or unreadable\")\n        \n        # Detect faces and extract embeddings\n        faces = app.get(img)\n        if len(faces) > 0:\n            return faces[0].embedding  # Return first detected face embedding\n        else:\n            print(f\"No face detected in {image_path}\")\n            return None\n    except Exception as e:\n        print(f\"Error processing {image_path}: {e}\")\n        return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:57:32.971667Z","iopub.execute_input":"2025-03-23T21:57:32.971979Z","iopub.status.idle":"2025-03-23T21:57:42.997015Z","shell.execute_reply.started":"2025-03-23T21:57:32.971952Z","shell.execute_reply":"2025-03-23T21:57:42.995943Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.20). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n  check_for_updates()\n","output_type":"stream"},{"name":"stdout","text":"Using GPU\ndownload_path: /root/.insightface/models/buffalo_l\nDownloading /root/.insightface/models/buffalo_l.zip from https://github.com/deepinsight/insightface/releases/download/v0.7/buffalo_l.zip...\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 281857/281857 [00:03<00:00, 83791.81KB/s]\n","output_type":"stream"},{"name":"stdout","text":"Applied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\nfind model: /root/.insightface/models/buffalo_l/1k3d68.onnx landmark_3d_68 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\nfind model: /root/.insightface/models/buffalo_l/2d106det.onnx landmark_2d_106 ['None', 3, 192, 192] 0.0 1.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\nfind model: /root/.insightface/models/buffalo_l/det_10g.onnx detection [1, 3, '?', '?'] 127.5 128.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\nfind model: /root/.insightface/models/buffalo_l/genderage.onnx genderage ['None', 3, 96, 96] 0.0 1.0\nApplied providers: ['CUDAExecutionProvider', 'CPUExecutionProvider'], with options: {'CPUExecutionProvider': {}, 'CUDAExecutionProvider': {'sdpa_kernel': '0', 'use_tf32': '1', 'fuse_conv_bias': '0', 'prefer_nhwc': '0', 'tunable_op_max_tuning_duration_ms': '0', 'enable_skip_layer_norm_strict_mode': '0', 'tunable_op_tuning_enable': '0', 'tunable_op_enable': '0', 'use_ep_level_unified_stream': '0', 'device_id': '0', 'has_user_compute_stream': '0', 'gpu_external_empty_cache': '0', 'cudnn_conv_algo_search': 'EXHAUSTIVE', 'cudnn_conv1d_pad_to_nc1d': '0', 'gpu_mem_limit': '18446744073709551615', 'gpu_external_alloc': '0', 'gpu_external_free': '0', 'arena_extend_strategy': 'kNextPowerOfTwo', 'do_copy_in_default_stream': '1', 'enable_cuda_graph': '0', 'user_compute_stream': '0', 'cudnn_conv_use_max_workspace': '1'}}\nfind model: /root/.insightface/models/buffalo_l/w600k_r50.onnx recognition ['None', 3, 112, 112] 127.5 127.5\nset det-size: (160, 160)\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-234bf6d49a41>\u001b[0m in \u001b[0;36m<cell line: 33>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error processing {image_path}: {e}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Applied Providers:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mproviders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mAttributeError\u001b[0m: 'FaceAnalysis' object has no attribute 'providers'"],"ename":"AttributeError","evalue":"'FaceAnalysis' object has no attribute 'providers'","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"train_embeddings = {}\n\ntotal_persons = len(train_images)\nprint(f\"Starting embedding extraction for {total_persons} persons.\")\n\nfor i, (person, img_paths) in enumerate(train_images.items(), start=1):\n    print(f\"\\nProcessing person {i}/{total_persons}: {person} ({len(img_paths)} images)\")\n    \n    embeddings = [get_embedding(img) for img in img_paths if get_embedding(img) is not None]\n\n    if embeddings:\n        train_embeddings[person] = np.mean(embeddings, axis=0)  # Average embedding\n        #print(f\"Computed embedding for {person} (from {len(embeddings)} images)\")\n    else:\n        print(f\" No valid embeddings for {person}\")\n\nprint(f\"\\nComputed embeddings for {len(train_embeddings)} unique persons.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T21:57:49.374739Z","iopub.execute_input":"2025-03-23T21:57:49.375074Z","iopub.status.idle":"2025-03-23T22:04:20.970499Z","shell.execute_reply.started":"2025-03-23T21:57:49.375038Z","shell.execute_reply":"2025-03-23T22:04:20.969553Z"}},"outputs":[{"name":"stdout","text":"Starting embedding extraction for 125 persons.\n\nProcessing person 1/125: person_0 (14 images)\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n","output_type":"stream"},{"name":"stdout","text":"\nProcessing person 2/125: person_1 (31 images)\n\nProcessing person 3/125: person_10 (5 images)\n\nProcessing person 4/125: person_100 (77 images)\n\nProcessing person 5/125: person_101 (53 images)\n\nProcessing person 6/125: person_102 (36 images)\n\nProcessing person 7/125: person_103 (50 images)\n\nProcessing person 8/125: person_104 (21 images)\n\nProcessing person 9/125: person_105 (49 images)\n\nProcessing person 10/125: person_106 (33 images)\n\nProcessing person 11/125: person_107 (191 images)\n\nProcessing person 12/125: person_108 (22 images)\n\nProcessing person 13/125: person_109 (35 images)\n\nProcessing person 14/125: person_11 (26 images)\n\nProcessing person 15/125: person_110 (79 images)\n\nProcessing person 16/125: person_111 (18 images)\n\nProcessing person 17/125: person_112 (59 images)\n\nProcessing person 18/125: person_113 (52 images)\n\nProcessing person 19/125: person_114 (110 images)\n\nProcessing person 20/125: person_115 (23 images)\n\nProcessing person 21/125: person_116 (75 images)\n\nProcessing person 22/125: person_117 (245 images)\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_117/1867.jpg\n\nProcessing person 23/125: person_118 (35 images)\n\nProcessing person 24/125: person_119 (25 images)\n\nProcessing person 25/125: person_12 (30 images)\n\nProcessing person 26/125: person_120 (24 images)\n\nProcessing person 27/125: person_121 (24 images)\n\nProcessing person 28/125: person_122 (7 images)\n\nProcessing person 29/125: person_123 (68 images)\n\nProcessing person 30/125: person_124 (63 images)\n\nProcessing person 31/125: person_13 (63 images)\n\nProcessing person 32/125: person_14 (69 images)\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_14/2435.jpg\n\nProcessing person 33/125: person_15 (86 images)\n\nProcessing person 34/125: person_16 (68 images)\n\nProcessing person 35/125: person_17 (12 images)\n\nProcessing person 36/125: person_18 (68 images)\n\nProcessing person 37/125: person_19 (203 images)\n\nProcessing person 38/125: person_2 (18 images)\n\nProcessing person 39/125: person_20 (17 images)\n\nProcessing person 40/125: person_21 (15 images)\n\nProcessing person 41/125: person_22 (63 images)\n\nProcessing person 42/125: person_23 (71 images)\n\nProcessing person 43/125: person_24 (52 images)\n\nProcessing person 44/125: person_25 (37 images)\n\nProcessing person 45/125: person_26 (26 images)\n\nProcessing person 46/125: person_27 (10 images)\n\nProcessing person 47/125: person_28 (55 images)\n\nProcessing person 48/125: person_29 (73 images)\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_29/3605.jpg\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_29/3638.jpg\n\nProcessing person 49/125: person_3 (54 images)\n\nProcessing person 50/125: person_30 (37 images)\n\nProcessing person 51/125: person_31 (25 images)\n\nProcessing person 52/125: person_32 (56 images)\n\nProcessing person 53/125: person_33 (60 images)\n\nProcessing person 54/125: person_34 (48 images)\n\nProcessing person 55/125: person_35 (91 images)\n\nProcessing person 56/125: person_36 (35 images)\n\nProcessing person 57/125: person_37 (21 images)\n\nProcessing person 58/125: person_38 (55 images)\n\nProcessing person 59/125: person_39 (16 images)\n\nProcessing person 60/125: person_4 (55 images)\n\nProcessing person 61/125: person_40 (98 images)\n\nProcessing person 62/125: person_41 (51 images)\n\nProcessing person 63/125: person_42 (45 images)\n\nProcessing person 64/125: person_43 (37 images)\n\nProcessing person 65/125: person_44 (42 images)\n\nProcessing person 66/125: person_45 (96 images)\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_45/4959.jpg\n\nProcessing person 67/125: person_46 (67 images)\n\nProcessing person 68/125: person_47 (56 images)\n\nProcessing person 69/125: person_48 (10 images)\n\nProcessing person 70/125: person_49 (73 images)\n\nProcessing person 71/125: person_5 (20 images)\n\nProcessing person 72/125: person_50 (76 images)\n\nProcessing person 73/125: person_51 (62 images)\n\nProcessing person 74/125: person_52 (39 images)\n\nProcessing person 75/125: person_53 (38 images)\n\nProcessing person 76/125: person_54 (32 images)\n\nProcessing person 77/125: person_55 (31 images)\n\nProcessing person 78/125: person_56 (41 images)\n\nProcessing person 79/125: person_57 (32 images)\n\nProcessing person 80/125: person_58 (30 images)\n\nProcessing person 81/125: person_59 (47 images)\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_59/5914.jpg\n\nProcessing person 82/125: person_6 (33 images)\n\nProcessing person 83/125: person_60 (16 images)\n\nProcessing person 84/125: person_61 (94 images)\n\nProcessing person 85/125: person_62 (72 images)\n\nProcessing person 86/125: person_63 (67 images)\n\nProcessing person 87/125: person_64 (17 images)\n\nProcessing person 88/125: person_65 (43 images)\n\nProcessing person 89/125: person_66 (64 images)\n\nProcessing person 90/125: person_67 (85 images)\n\nProcessing person 91/125: person_68 (46 images)\n\nProcessing person 92/125: person_69 (42 images)\n\nProcessing person 93/125: person_7 (98 images)\n\nProcessing person 94/125: person_70 (62 images)\n\nProcessing person 95/125: person_71 (29 images)\n\nProcessing person 96/125: person_72 (21 images)\n\nProcessing person 97/125: person_73 (67 images)\n\nProcessing person 98/125: person_74 (49 images)\n\nProcessing person 99/125: person_75 (80 images)\n\nProcessing person 100/125: person_76 (33 images)\n\nProcessing person 101/125: person_77 (49 images)\n\nProcessing person 102/125: person_78 (56 images)\n\nProcessing person 103/125: person_79 (70 images)\n\nProcessing person 104/125: person_8 (21 images)\n\nProcessing person 105/125: person_80 (77 images)\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_80/7700.jpg\n\nProcessing person 106/125: person_81 (54 images)\n\nProcessing person 107/125: person_82 (53 images)\n\nProcessing person 108/125: person_83 (98 images)\n\nProcessing person 109/125: person_84 (32 images)\n\nProcessing person 110/125: person_85 (54 images)\n\nProcessing person 111/125: person_86 (19 images)\n\nProcessing person 112/125: person_87 (37 images)\n\nProcessing person 113/125: person_88 (163 images)\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_88/8306.jpg\n\nProcessing person 114/125: person_89 (30 images)\n\nProcessing person 115/125: person_9 (54 images)\n\nProcessing person 116/125: person_90 (283 images)\n\nProcessing person 117/125: person_91 (46 images)\n\nProcessing person 118/125: person_92 (84 images)\n\nProcessing person 119/125: person_93 (48 images)\n\nProcessing person 120/125: person_94 (29 images)\n\nProcessing person 121/125: person_95 (60 images)\n\nProcessing person 122/125: person_96 (69 images)\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/train/person_96/9452.jpg\n\nProcessing person 123/125: person_97 (32 images)\n\nProcessing person 124/125: person_98 (62 images)\n\nProcessing person 125/125: person_99 (68 images)\n\nComputed embeddings for 125 unique persons.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"test_folder = \"/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/test\"\ntest_images = [os.path.join(test_folder, img) for img in os.listdir(test_folder) if img.endswith(('.jpg', '.png', '.jpeg'))]\nprint(f\"Found {len(test_images)} test images.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:04:24.673920Z","iopub.execute_input":"2025-03-23T22:04:24.674586Z","iopub.status.idle":"2025-03-23T22:04:24.719083Z","shell.execute_reply.started":"2025-03-23T22:04:24.674550Z","shell.execute_reply":"2025-03-23T22:04:24.718165Z"}},"outputs":[{"name":"stdout","text":"Found 4734 test images.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def find_best_match(test_embedding, threshold=0.5):\n    \"\"\"Find the closest match from the training embeddings.\"\"\"\n    best_match = None\n    best_score = float('inf')  # Lower is better for cosine distance\n    \n    for person, emb in train_embeddings.items():\n        score = cosine(test_embedding, emb)\n        if score < best_score:\n            best_score = score\n            best_match = person\n\n    return best_match if best_score < threshold else \"doesn\\'t_exist\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:29:46.108131Z","iopub.execute_input":"2025-03-23T22:29:46.108514Z","iopub.status.idle":"2025-03-23T22:29:46.113545Z","shell.execute_reply.started":"2025-03-23T22:29:46.108486Z","shell.execute_reply":"2025-03-23T22:29:46.112616Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"import csv\nimport os\n\n# Define file paths\nsubmission_file = \"/kaggle/input/surveillance-for-retail-stores/submission_file.csv\"\noutput_csv_path = \"/kaggle/working/predictions2.csv\"\n\n# Extract image numbers from the submission file\nsubmission_order = []\nwith open(submission_file, mode=\"r\", encoding=\"utf-8\") as file:\n    reader = csv.reader(file)\n    next(reader)  # Skip header\n    for row in reader:\n        try:\n            parsed_obj = eval(row[2])  # Safely evaluate dictionary string\n            if isinstance(parsed_obj, dict) and \"image\" in parsed_obj:\n                image_filename = os.path.basename(parsed_obj[\"image\"])  # Extract only filename\n                submission_order.append(image_filename)  # Store ordered image filenames\n            else:\n                print(f\"Unexpected format in submission file row: {row}\")\n        except Exception as e:\n            print(f\"Error parsing row {row}: {e}\")\n\nprint(f\"Loaded {len(submission_order)} image filenames from submission file.\")\n\npredictions_dict = {}\n\nfor test_img in submission_order:  # Ensure inference follows submission order\n    test_emb = get_embedding(os.path.join(\"/kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/test\", test_img))  # Compute embedding\n    if test_emb is not None:\n        match = find_best_match(test_emb)  # Find best match\n    else:\n        match = \"doesn\\'t_exist\"\n    \n    predictions_dict[test_img] = match  \n\nprint(f\"Generated {len(predictions_dict)} predictions.\")\n\nwith open(output_csv_path, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n    writer = csv.writer(file,quoting=csv.QUOTE_ALL)\n    writer.writerow([\"ID\", \"frame\", \"objects\", \"objective\"])  # Write header\n\n    for index, image_filename in enumerate(submission_order, start=429):  \n        if image_filename in predictions_dict:\n            gt_label = predictions_dict[image_filename]  # Get label from dictionary\n            short_image_path = os.path.join(\"test_set\", image_filename)  # Reconstruct path\n\n            if gt_label == \"doesn\\'t_exist\":\n                obj_str = f'{{\"gt\": \"{gt_label}\", \"image\": \"{short_image_path}\"}}'  # Use double quotes for \"doesn't exist\"\n            else:\n                obj_str = f\"{{'gt': '{gt_label}', 'image': '{short_image_path}'}}\"  # Use single quotes for other cases\n\n            # Write row in correct format\n            writer.writerow([index, -1.0, obj_str, \"face_reid\"])\n        else:\n            print(f\"Missing prediction for {image_filename}\")\n\nprint(f\"Predictions saved to {output_csv_path}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:29:50.143873Z","iopub.execute_input":"2025-03-23T22:29:50.144174Z","iopub.status.idle":"2025-03-23T22:32:04.258622Z","shell.execute_reply.started":"2025-03-23T22:29:50.144150Z","shell.execute_reply":"2025-03-23T22:32:04.257650Z"}},"outputs":[{"name":"stdout","text":"Unexpected format in submission file row: ['0', '1.0', '[]', 'tracking']\nUnexpected format in submission file row: ['1', '2.0', '[]', 'tracking']\nUnexpected format in submission file row: ['2', '3.0', '[]', 'tracking']\nUnexpected format in submission file row: ['3', '4.0', '[]', 'tracking']\nUnexpected format in submission file row: ['4', '5.0', '[]', 'tracking']\nUnexpected format in submission file row: ['5', '6.0', '[]', 'tracking']\nUnexpected format in submission file row: ['6', '7.0', '[]', 'tracking']\nUnexpected format in submission file row: ['7', '8.0', '[]', 'tracking']\nUnexpected format in submission file row: ['8', '9.0', '[]', 'tracking']\nUnexpected format in submission file row: ['9', '10.0', '[]', 'tracking']\nUnexpected format in submission file row: ['10', '11.0', '[]', 'tracking']\nUnexpected format in submission file row: ['11', '12.0', '[]', 'tracking']\nUnexpected format in submission file row: ['12', '13.0', '[]', 'tracking']\nUnexpected format in submission file row: ['13', '14.0', '[]', 'tracking']\nUnexpected format in submission file row: ['14', '15.0', '[]', 'tracking']\nUnexpected format in submission file row: ['15', '16.0', '[]', 'tracking']\nUnexpected format in submission file row: ['16', '17.0', '[]', 'tracking']\nUnexpected format in submission file row: ['17', '18.0', '[]', 'tracking']\nUnexpected format in submission file row: ['18', '19.0', '[]', 'tracking']\nUnexpected format in submission file row: ['19', '20.0', '[]', 'tracking']\nUnexpected format in submission file row: ['20', '21.0', '[]', 'tracking']\nUnexpected format in submission file row: ['21', '22.0', '[]', 'tracking']\nUnexpected format in submission file row: ['22', '23.0', '[]', 'tracking']\nUnexpected format in submission file row: ['23', '24.0', '[]', 'tracking']\nUnexpected format in submission file row: ['24', '25.0', '[]', 'tracking']\nUnexpected format in submission file row: ['25', '26.0', '[]', 'tracking']\nUnexpected format in submission file row: ['26', '27.0', '[]', 'tracking']\nUnexpected format in submission file row: ['27', '28.0', '[]', 'tracking']\nUnexpected format in submission file row: ['28', '29.0', '[]', 'tracking']\nUnexpected format in submission file row: ['29', '30.0', '[]', 'tracking']\nUnexpected format in submission file row: ['30', '31.0', '[]', 'tracking']\nUnexpected format in submission file row: ['31', '32.0', '[]', 'tracking']\nUnexpected format in submission file row: ['32', '33.0', '[]', 'tracking']\nUnexpected format in submission file row: ['33', '34.0', '[]', 'tracking']\nUnexpected format in submission file row: ['34', '35.0', '[]', 'tracking']\nUnexpected format in submission file row: ['35', '36.0', '[]', 'tracking']\nUnexpected format in submission file row: ['36', '37.0', '[]', 'tracking']\nUnexpected format in submission file row: ['37', '38.0', '[]', 'tracking']\nUnexpected format in submission file row: ['38', '39.0', '[]', 'tracking']\nUnexpected format in submission file row: ['39', '40.0', '[]', 'tracking']\nUnexpected format in submission file row: ['40', '41.0', '[]', 'tracking']\nUnexpected format in submission file row: ['41', '42.0', '[]', 'tracking']\nUnexpected format in submission file row: ['42', '43.0', '[]', 'tracking']\nUnexpected format in submission file row: ['43', '44.0', '[]', 'tracking']\nUnexpected format in submission file row: ['44', '45.0', '[]', 'tracking']\nUnexpected format in submission file row: ['45', '46.0', '[]', 'tracking']\nUnexpected format in submission file row: ['46', '47.0', '[]', 'tracking']\nUnexpected format in submission file row: ['47', '48.0', '[]', 'tracking']\nUnexpected format in submission file row: ['48', '49.0', '[]', 'tracking']\nUnexpected format in submission file row: ['49', '50.0', '[]', 'tracking']\nUnexpected format in submission file row: ['50', '51.0', '[]', 'tracking']\nUnexpected format in submission file row: ['51', '52.0', '[]', 'tracking']\nUnexpected format in submission file row: ['52', '53.0', '[]', 'tracking']\nUnexpected format in submission file row: ['53', '54.0', '[]', 'tracking']\nUnexpected format in submission file row: ['54', '55.0', '[]', 'tracking']\nUnexpected format in submission file row: ['55', '56.0', '[]', 'tracking']\nUnexpected format in submission file row: ['56', '57.0', '[]', 'tracking']\nUnexpected format in submission file row: ['57', '58.0', '[]', 'tracking']\nUnexpected format in submission file row: ['58', '59.0', '[]', 'tracking']\nUnexpected format in submission file row: ['59', '60.0', '[]', 'tracking']\nUnexpected format in submission file row: ['60', '61.0', '[]', 'tracking']\nUnexpected format in submission file row: ['61', '62.0', '[]', 'tracking']\nUnexpected format in submission file row: ['62', '63.0', '[]', 'tracking']\nUnexpected format in submission file row: ['63', '64.0', '[]', 'tracking']\nUnexpected format in submission file row: ['64', '65.0', '[]', 'tracking']\nUnexpected format in submission file row: ['65', '66.0', '[]', 'tracking']\nUnexpected format in submission file row: ['66', '67.0', '[]', 'tracking']\nUnexpected format in submission file row: ['67', '68.0', '[]', 'tracking']\nUnexpected format in submission file row: ['68', '69.0', '[]', 'tracking']\nUnexpected format in submission file row: ['69', '70.0', '[]', 'tracking']\nUnexpected format in submission file row: ['70', '71.0', '[]', 'tracking']\nUnexpected format in submission file row: ['71', '72.0', '[]', 'tracking']\nUnexpected format in submission file row: ['72', '73.0', '[]', 'tracking']\nUnexpected format in submission file row: ['73', '74.0', '[]', 'tracking']\nUnexpected format in submission file row: ['74', '75.0', '[]', 'tracking']\nUnexpected format in submission file row: ['75', '76.0', '[]', 'tracking']\nUnexpected format in submission file row: ['76', '77.0', '[]', 'tracking']\nUnexpected format in submission file row: ['77', '78.0', '[]', 'tracking']\nUnexpected format in submission file row: ['78', '79.0', '[]', 'tracking']\nUnexpected format in submission file row: ['79', '80.0', '[]', 'tracking']\nUnexpected format in submission file row: ['80', '81.0', '[]', 'tracking']\nUnexpected format in submission file row: ['81', '82.0', '[]', 'tracking']\nUnexpected format in submission file row: ['82', '83.0', '[]', 'tracking']\nUnexpected format in submission file row: ['83', '84.0', '[]', 'tracking']\nUnexpected format in submission file row: ['84', '85.0', '[]', 'tracking']\nUnexpected format in submission file row: ['85', '86.0', '[]', 'tracking']\nUnexpected format in submission file row: ['86', '87.0', '[]', 'tracking']\nUnexpected format in submission file row: ['87', '88.0', '[]', 'tracking']\nUnexpected format in submission file row: ['88', '89.0', '[]', 'tracking']\nUnexpected format in submission file row: ['89', '90.0', '[]', 'tracking']\nUnexpected format in submission file row: ['90', '91.0', '[]', 'tracking']\nUnexpected format in submission file row: ['91', '92.0', '[]', 'tracking']\nUnexpected format in submission file row: ['92', '93.0', '[]', 'tracking']\nUnexpected format in submission file row: ['93', '94.0', '[]', 'tracking']\nUnexpected format in submission file row: ['94', '95.0', '[]', 'tracking']\nUnexpected format in submission file row: ['95', '96.0', '[]', 'tracking']\nUnexpected format in submission file row: ['96', '97.0', '[]', 'tracking']\nUnexpected format in submission file row: ['97', '98.0', '[]', 'tracking']\nUnexpected format in submission file row: ['98', '99.0', '[]', 'tracking']\nUnexpected format in submission file row: ['99', '100.0', '[]', 'tracking']\nUnexpected format in submission file row: ['100', '101.0', '[]', 'tracking']\nUnexpected format in submission file row: ['101', '102.0', '[]', 'tracking']\nUnexpected format in submission file row: ['102', '103.0', '[]', 'tracking']\nUnexpected format in submission file row: ['103', '104.0', '[]', 'tracking']\nUnexpected format in submission file row: ['104', '105.0', '[]', 'tracking']\nUnexpected format in submission file row: ['105', '106.0', '[]', 'tracking']\nUnexpected format in submission file row: ['106', '107.0', '[]', 'tracking']\nUnexpected format in submission file row: ['107', '108.0', '[]', 'tracking']\nUnexpected format in submission file row: ['108', '109.0', '[]', 'tracking']\nUnexpected format in submission file row: ['109', '110.0', '[]', 'tracking']\nUnexpected format in submission file row: ['110', '111.0', '[]', 'tracking']\nUnexpected format in submission file row: ['111', '112.0', '[]', 'tracking']\nUnexpected format in submission file row: ['112', '113.0', '[]', 'tracking']\nUnexpected format in submission file row: ['113', '114.0', '[]', 'tracking']\nUnexpected format in submission file row: ['114', '115.0', '[]', 'tracking']\nUnexpected format in submission file row: ['115', '116.0', '[]', 'tracking']\nUnexpected format in submission file row: ['116', '117.0', '[]', 'tracking']\nUnexpected format in submission file row: ['117', '118.0', '[]', 'tracking']\nUnexpected format in submission file row: ['118', '119.0', '[]', 'tracking']\nUnexpected format in submission file row: ['119', '120.0', '[]', 'tracking']\nUnexpected format in submission file row: ['120', '121.0', '[]', 'tracking']\nUnexpected format in submission file row: ['121', '122.0', '[]', 'tracking']\nUnexpected format in submission file row: ['122', '123.0', '[]', 'tracking']\nUnexpected format in submission file row: ['123', '124.0', '[]', 'tracking']\nUnexpected format in submission file row: ['124', '125.0', '[]', 'tracking']\nUnexpected format in submission file row: ['125', '126.0', '[]', 'tracking']\nUnexpected format in submission file row: ['126', '127.0', '[]', 'tracking']\nUnexpected format in submission file row: ['127', '128.0', '[]', 'tracking']\nUnexpected format in submission file row: ['128', '129.0', '[]', 'tracking']\nUnexpected format in submission file row: ['129', '130.0', '[]', 'tracking']\nUnexpected format in submission file row: ['130', '131.0', '[]', 'tracking']\nUnexpected format in submission file row: ['131', '132.0', '[]', 'tracking']\nUnexpected format in submission file row: ['132', '133.0', '[]', 'tracking']\nUnexpected format in submission file row: ['133', '134.0', '[]', 'tracking']\nUnexpected format in submission file row: ['134', '135.0', '[]', 'tracking']\nUnexpected format in submission file row: ['135', '136.0', '[]', 'tracking']\nUnexpected format in submission file row: ['136', '137.0', '[]', 'tracking']\nUnexpected format in submission file row: ['137', '138.0', '[]', 'tracking']\nUnexpected format in submission file row: ['138', '139.0', '[]', 'tracking']\nUnexpected format in submission file row: ['139', '140.0', '[]', 'tracking']\nUnexpected format in submission file row: ['140', '141.0', '[]', 'tracking']\nUnexpected format in submission file row: ['141', '142.0', '[]', 'tracking']\nUnexpected format in submission file row: ['142', '143.0', '[]', 'tracking']\nUnexpected format in submission file row: ['143', '144.0', '[]', 'tracking']\nUnexpected format in submission file row: ['144', '145.0', '[]', 'tracking']\nUnexpected format in submission file row: ['145', '146.0', '[]', 'tracking']\nUnexpected format in submission file row: ['146', '147.0', '[]', 'tracking']\nUnexpected format in submission file row: ['147', '148.0', '[]', 'tracking']\nUnexpected format in submission file row: ['148', '149.0', '[]', 'tracking']\nUnexpected format in submission file row: ['149', '150.0', '[]', 'tracking']\nUnexpected format in submission file row: ['150', '151.0', '[]', 'tracking']\nUnexpected format in submission file row: ['151', '152.0', '[]', 'tracking']\nUnexpected format in submission file row: ['152', '153.0', '[]', 'tracking']\nUnexpected format in submission file row: ['153', '154.0', '[]', 'tracking']\nUnexpected format in submission file row: ['154', '155.0', '[]', 'tracking']\nUnexpected format in submission file row: ['155', '156.0', '[]', 'tracking']\nUnexpected format in submission file row: ['156', '157.0', '[]', 'tracking']\nUnexpected format in submission file row: ['157', '158.0', '[]', 'tracking']\nUnexpected format in submission file row: ['158', '159.0', '[]', 'tracking']\nUnexpected format in submission file row: ['159', '160.0', '[]', 'tracking']\nUnexpected format in submission file row: ['160', '161.0', '[]', 'tracking']\nUnexpected format in submission file row: ['161', '162.0', '[]', 'tracking']\nUnexpected format in submission file row: ['162', '163.0', '[]', 'tracking']\nUnexpected format in submission file row: ['163', '164.0', '[]', 'tracking']\nUnexpected format in submission file row: ['164', '165.0', '[]', 'tracking']\nUnexpected format in submission file row: ['165', '166.0', '[]', 'tracking']\nUnexpected format in submission file row: ['166', '167.0', '[]', 'tracking']\nUnexpected format in submission file row: ['167', '168.0', '[]', 'tracking']\nUnexpected format in submission file row: ['168', '169.0', '[]', 'tracking']\nUnexpected format in submission file row: ['169', '170.0', '[]', 'tracking']\nUnexpected format in submission file row: ['170', '171.0', '[]', 'tracking']\nUnexpected format in submission file row: ['171', '172.0', '[]', 'tracking']\nUnexpected format in submission file row: ['172', '173.0', '[]', 'tracking']\nUnexpected format in submission file row: ['173', '174.0', '[]', 'tracking']\nUnexpected format in submission file row: ['174', '175.0', '[]', 'tracking']\nUnexpected format in submission file row: ['175', '176.0', '[]', 'tracking']\nUnexpected format in submission file row: ['176', '177.0', '[]', 'tracking']\nUnexpected format in submission file row: ['177', '178.0', '[]', 'tracking']\nUnexpected format in submission file row: ['178', '179.0', '[]', 'tracking']\nUnexpected format in submission file row: ['179', '180.0', '[]', 'tracking']\nUnexpected format in submission file row: ['180', '181.0', '[]', 'tracking']\nUnexpected format in submission file row: ['181', '182.0', '[]', 'tracking']\nUnexpected format in submission file row: ['182', '183.0', '[]', 'tracking']\nUnexpected format in submission file row: ['183', '184.0', '[]', 'tracking']\nUnexpected format in submission file row: ['184', '185.0', '[]', 'tracking']\nUnexpected format in submission file row: ['185', '186.0', '[]', 'tracking']\nUnexpected format in submission file row: ['186', '187.0', '[]', 'tracking']\nUnexpected format in submission file row: ['187', '188.0', '[]', 'tracking']\nUnexpected format in submission file row: ['188', '189.0', '[]', 'tracking']\nUnexpected format in submission file row: ['189', '190.0', '[]', 'tracking']\nUnexpected format in submission file row: ['190', '191.0', '[]', 'tracking']\nUnexpected format in submission file row: ['191', '192.0', '[]', 'tracking']\nUnexpected format in submission file row: ['192', '193.0', '[]', 'tracking']\nUnexpected format in submission file row: ['193', '194.0', '[]', 'tracking']\nUnexpected format in submission file row: ['194', '195.0', '[]', 'tracking']\nUnexpected format in submission file row: ['195', '196.0', '[]', 'tracking']\nUnexpected format in submission file row: ['196', '197.0', '[]', 'tracking']\nUnexpected format in submission file row: ['197', '198.0', '[]', 'tracking']\nUnexpected format in submission file row: ['198', '199.0', '[]', 'tracking']\nUnexpected format in submission file row: ['199', '200.0', '[]', 'tracking']\nUnexpected format in submission file row: ['200', '201.0', '[]', 'tracking']\nUnexpected format in submission file row: ['201', '202.0', '[]', 'tracking']\nUnexpected format in submission file row: ['202', '203.0', '[]', 'tracking']\nUnexpected format in submission file row: ['203', '204.0', '[]', 'tracking']\nUnexpected format in submission file row: ['204', '205.0', '[]', 'tracking']\nUnexpected format in submission file row: ['205', '206.0', '[]', 'tracking']\nUnexpected format in submission file row: ['206', '207.0', '[]', 'tracking']\nUnexpected format in submission file row: ['207', '208.0', '[]', 'tracking']\nUnexpected format in submission file row: ['208', '209.0', '[]', 'tracking']\nUnexpected format in submission file row: ['209', '210.0', '[]', 'tracking']\nUnexpected format in submission file row: ['210', '211.0', '[]', 'tracking']\nUnexpected format in submission file row: ['211', '212.0', '[]', 'tracking']\nUnexpected format in submission file row: ['212', '213.0', '[]', 'tracking']\nUnexpected format in submission file row: ['213', '214.0', '[]', 'tracking']\nUnexpected format in submission file row: ['214', '215.0', '[]', 'tracking']\nUnexpected format in submission file row: ['215', '216.0', '[]', 'tracking']\nUnexpected format in submission file row: ['216', '217.0', '[]', 'tracking']\nUnexpected format in submission file row: ['217', '218.0', '[]', 'tracking']\nUnexpected format in submission file row: ['218', '219.0', '[]', 'tracking']\nUnexpected format in submission file row: ['219', '220.0', '[]', 'tracking']\nUnexpected format in submission file row: ['220', '221.0', '[]', 'tracking']\nUnexpected format in submission file row: ['221', '222.0', '[]', 'tracking']\nUnexpected format in submission file row: ['222', '223.0', '[]', 'tracking']\nUnexpected format in submission file row: ['223', '224.0', '[]', 'tracking']\nUnexpected format in submission file row: ['224', '225.0', '[]', 'tracking']\nUnexpected format in submission file row: ['225', '226.0', '[]', 'tracking']\nUnexpected format in submission file row: ['226', '227.0', '[]', 'tracking']\nUnexpected format in submission file row: ['227', '228.0', '[]', 'tracking']\nUnexpected format in submission file row: ['228', '229.0', '[]', 'tracking']\nUnexpected format in submission file row: ['229', '230.0', '[]', 'tracking']\nUnexpected format in submission file row: ['230', '231.0', '[]', 'tracking']\nUnexpected format in submission file row: ['231', '232.0', '[]', 'tracking']\nUnexpected format in submission file row: ['232', '233.0', '[]', 'tracking']\nUnexpected format in submission file row: ['233', '234.0', '[]', 'tracking']\nUnexpected format in submission file row: ['234', '235.0', '[]', 'tracking']\nUnexpected format in submission file row: ['235', '236.0', '[]', 'tracking']\nUnexpected format in submission file row: ['236', '237.0', '[]', 'tracking']\nUnexpected format in submission file row: ['237', '238.0', '[]', 'tracking']\nUnexpected format in submission file row: ['238', '239.0', '[]', 'tracking']\nUnexpected format in submission file row: ['239', '240.0', '[]', 'tracking']\nUnexpected format in submission file row: ['240', '241.0', '[]', 'tracking']\nUnexpected format in submission file row: ['241', '242.0', '[]', 'tracking']\nUnexpected format in submission file row: ['242', '243.0', '[]', 'tracking']\nUnexpected format in submission file row: ['243', '244.0', '[]', 'tracking']\nUnexpected format in submission file row: ['244', '245.0', '[]', 'tracking']\nUnexpected format in submission file row: ['245', '246.0', '[]', 'tracking']\nUnexpected format in submission file row: ['246', '247.0', '[]', 'tracking']\nUnexpected format in submission file row: ['247', '248.0', '[]', 'tracking']\nUnexpected format in submission file row: ['248', '249.0', '[]', 'tracking']\nUnexpected format in submission file row: ['249', '250.0', '[]', 'tracking']\nUnexpected format in submission file row: ['250', '251.0', '[]', 'tracking']\nUnexpected format in submission file row: ['251', '252.0', '[]', 'tracking']\nUnexpected format in submission file row: ['252', '253.0', '[]', 'tracking']\nUnexpected format in submission file row: ['253', '254.0', '[]', 'tracking']\nUnexpected format in submission file row: ['254', '255.0', '[]', 'tracking']\nUnexpected format in submission file row: ['255', '256.0', '[]', 'tracking']\nUnexpected format in submission file row: ['256', '257.0', '[]', 'tracking']\nUnexpected format in submission file row: ['257', '258.0', '[]', 'tracking']\nUnexpected format in submission file row: ['258', '259.0', '[]', 'tracking']\nUnexpected format in submission file row: ['259', '260.0', '[]', 'tracking']\nUnexpected format in submission file row: ['260', '261.0', '[]', 'tracking']\nUnexpected format in submission file row: ['261', '262.0', '[]', 'tracking']\nUnexpected format in submission file row: ['262', '263.0', '[]', 'tracking']\nUnexpected format in submission file row: ['263', '264.0', '[]', 'tracking']\nUnexpected format in submission file row: ['264', '265.0', '[]', 'tracking']\nUnexpected format in submission file row: ['265', '266.0', '[]', 'tracking']\nUnexpected format in submission file row: ['266', '267.0', '[]', 'tracking']\nUnexpected format in submission file row: ['267', '268.0', '[]', 'tracking']\nUnexpected format in submission file row: ['268', '269.0', '[]', 'tracking']\nUnexpected format in submission file row: ['269', '270.0', '[]', 'tracking']\nUnexpected format in submission file row: ['270', '271.0', '[]', 'tracking']\nUnexpected format in submission file row: ['271', '272.0', '[]', 'tracking']\nUnexpected format in submission file row: ['272', '273.0', '[]', 'tracking']\nUnexpected format in submission file row: ['273', '274.0', '[]', 'tracking']\nUnexpected format in submission file row: ['274', '275.0', '[]', 'tracking']\nUnexpected format in submission file row: ['275', '276.0', '[]', 'tracking']\nUnexpected format in submission file row: ['276', '277.0', '[]', 'tracking']\nUnexpected format in submission file row: ['277', '278.0', '[]', 'tracking']\nUnexpected format in submission file row: ['278', '279.0', '[]', 'tracking']\nUnexpected format in submission file row: ['279', '280.0', '[]', 'tracking']\nUnexpected format in submission file row: ['280', '281.0', '[]', 'tracking']\nUnexpected format in submission file row: ['281', '282.0', '[]', 'tracking']\nUnexpected format in submission file row: ['282', '283.0', '[]', 'tracking']\nUnexpected format in submission file row: ['283', '284.0', '[]', 'tracking']\nUnexpected format in submission file row: ['284', '285.0', '[]', 'tracking']\nUnexpected format in submission file row: ['285', '286.0', '[]', 'tracking']\nUnexpected format in submission file row: ['286', '287.0', '[]', 'tracking']\nUnexpected format in submission file row: ['287', '288.0', '[]', 'tracking']\nUnexpected format in submission file row: ['288', '289.0', '[]', 'tracking']\nUnexpected format in submission file row: ['289', '290.0', '[]', 'tracking']\nUnexpected format in submission file row: ['290', '291.0', '[]', 'tracking']\nUnexpected format in submission file row: ['291', '292.0', '[]', 'tracking']\nUnexpected format in submission file row: ['292', '293.0', '[]', 'tracking']\nUnexpected format in submission file row: ['293', '294.0', '[]', 'tracking']\nUnexpected format in submission file row: ['294', '295.0', '[]', 'tracking']\nUnexpected format in submission file row: ['295', '296.0', '[]', 'tracking']\nUnexpected format in submission file row: ['296', '297.0', '[]', 'tracking']\nUnexpected format in submission file row: ['297', '298.0', '[]', 'tracking']\nUnexpected format in submission file row: ['298', '299.0', '[]', 'tracking']\nUnexpected format in submission file row: ['299', '300.0', '[]', 'tracking']\nUnexpected format in submission file row: ['300', '301.0', '[]', 'tracking']\nUnexpected format in submission file row: ['301', '302.0', '[]', 'tracking']\nUnexpected format in submission file row: ['302', '303.0', '[]', 'tracking']\nUnexpected format in submission file row: ['303', '304.0', '[]', 'tracking']\nUnexpected format in submission file row: ['304', '305.0', '[]', 'tracking']\nUnexpected format in submission file row: ['305', '306.0', '[]', 'tracking']\nUnexpected format in submission file row: ['306', '307.0', '[]', 'tracking']\nUnexpected format in submission file row: ['307', '308.0', '[]', 'tracking']\nUnexpected format in submission file row: ['308', '309.0', '[]', 'tracking']\nUnexpected format in submission file row: ['309', '310.0', '[]', 'tracking']\nUnexpected format in submission file row: ['310', '311.0', '[]', 'tracking']\nUnexpected format in submission file row: ['311', '312.0', '[]', 'tracking']\nUnexpected format in submission file row: ['312', '313.0', '[]', 'tracking']\nUnexpected format in submission file row: ['313', '314.0', '[]', 'tracking']\nUnexpected format in submission file row: ['314', '315.0', '[]', 'tracking']\nUnexpected format in submission file row: ['315', '316.0', '[]', 'tracking']\nUnexpected format in submission file row: ['316', '317.0', '[]', 'tracking']\nUnexpected format in submission file row: ['317', '318.0', '[]', 'tracking']\nUnexpected format in submission file row: ['318', '319.0', '[]', 'tracking']\nUnexpected format in submission file row: ['319', '320.0', '[]', 'tracking']\nUnexpected format in submission file row: ['320', '321.0', '[]', 'tracking']\nUnexpected format in submission file row: ['321', '322.0', '[]', 'tracking']\nUnexpected format in submission file row: ['322', '323.0', '[]', 'tracking']\nUnexpected format in submission file row: ['323', '324.0', '[]', 'tracking']\nUnexpected format in submission file row: ['324', '325.0', '[]', 'tracking']\nUnexpected format in submission file row: ['325', '326.0', '[]', 'tracking']\nUnexpected format in submission file row: ['326', '327.0', '[]', 'tracking']\nUnexpected format in submission file row: ['327', '328.0', '[]', 'tracking']\nUnexpected format in submission file row: ['328', '329.0', '[]', 'tracking']\nUnexpected format in submission file row: ['329', '330.0', '[]', 'tracking']\nUnexpected format in submission file row: ['330', '331.0', '[]', 'tracking']\nUnexpected format in submission file row: ['331', '332.0', '[]', 'tracking']\nUnexpected format in submission file row: ['332', '333.0', '[]', 'tracking']\nUnexpected format in submission file row: ['333', '334.0', '[]', 'tracking']\nUnexpected format in submission file row: ['334', '335.0', '[]', 'tracking']\nUnexpected format in submission file row: ['335', '336.0', '[]', 'tracking']\nUnexpected format in submission file row: ['336', '337.0', '[]', 'tracking']\nUnexpected format in submission file row: ['337', '338.0', '[]', 'tracking']\nUnexpected format in submission file row: ['338', '339.0', '[]', 'tracking']\nUnexpected format in submission file row: ['339', '340.0', '[]', 'tracking']\nUnexpected format in submission file row: ['340', '341.0', '[]', 'tracking']\nUnexpected format in submission file row: ['341', '342.0', '[]', 'tracking']\nUnexpected format in submission file row: ['342', '343.0', '[]', 'tracking']\nUnexpected format in submission file row: ['343', '344.0', '[]', 'tracking']\nUnexpected format in submission file row: ['344', '345.0', '[]', 'tracking']\nUnexpected format in submission file row: ['345', '346.0', '[]', 'tracking']\nUnexpected format in submission file row: ['346', '347.0', '[]', 'tracking']\nUnexpected format in submission file row: ['347', '348.0', '[]', 'tracking']\nUnexpected format in submission file row: ['348', '349.0', '[]', 'tracking']\nUnexpected format in submission file row: ['349', '350.0', '[]', 'tracking']\nUnexpected format in submission file row: ['350', '351.0', '[]', 'tracking']\nUnexpected format in submission file row: ['351', '352.0', '[]', 'tracking']\nUnexpected format in submission file row: ['352', '353.0', '[]', 'tracking']\nUnexpected format in submission file row: ['353', '354.0', '[]', 'tracking']\nUnexpected format in submission file row: ['354', '355.0', '[]', 'tracking']\nUnexpected format in submission file row: ['355', '356.0', '[]', 'tracking']\nUnexpected format in submission file row: ['356', '357.0', '[]', 'tracking']\nUnexpected format in submission file row: ['357', '358.0', '[]', 'tracking']\nUnexpected format in submission file row: ['358', '359.0', '[]', 'tracking']\nUnexpected format in submission file row: ['359', '360.0', '[]', 'tracking']\nUnexpected format in submission file row: ['360', '361.0', '[]', 'tracking']\nUnexpected format in submission file row: ['361', '362.0', '[]', 'tracking']\nUnexpected format in submission file row: ['362', '363.0', '[]', 'tracking']\nUnexpected format in submission file row: ['363', '364.0', '[]', 'tracking']\nUnexpected format in submission file row: ['364', '365.0', '[]', 'tracking']\nUnexpected format in submission file row: ['365', '366.0', '[]', 'tracking']\nUnexpected format in submission file row: ['366', '367.0', '[]', 'tracking']\nUnexpected format in submission file row: ['367', '368.0', '[]', 'tracking']\nUnexpected format in submission file row: ['368', '369.0', '[]', 'tracking']\nUnexpected format in submission file row: ['369', '370.0', '[]', 'tracking']\nUnexpected format in submission file row: ['370', '371.0', '[]', 'tracking']\nUnexpected format in submission file row: ['371', '372.0', '[]', 'tracking']\nUnexpected format in submission file row: ['372', '373.0', '[]', 'tracking']\nUnexpected format in submission file row: ['373', '374.0', '[]', 'tracking']\nUnexpected format in submission file row: ['374', '375.0', '[]', 'tracking']\nUnexpected format in submission file row: ['375', '376.0', '[]', 'tracking']\nUnexpected format in submission file row: ['376', '377.0', '[]', 'tracking']\nUnexpected format in submission file row: ['377', '378.0', '[]', 'tracking']\nUnexpected format in submission file row: ['378', '379.0', '[]', 'tracking']\nUnexpected format in submission file row: ['379', '380.0', '[]', 'tracking']\nUnexpected format in submission file row: ['380', '381.0', '[]', 'tracking']\nUnexpected format in submission file row: ['381', '382.0', '[]', 'tracking']\nUnexpected format in submission file row: ['382', '383.0', '[]', 'tracking']\nUnexpected format in submission file row: ['383', '384.0', '[]', 'tracking']\nUnexpected format in submission file row: ['384', '385.0', '[]', 'tracking']\nUnexpected format in submission file row: ['385', '386.0', '[]', 'tracking']\nUnexpected format in submission file row: ['386', '387.0', '[]', 'tracking']\nUnexpected format in submission file row: ['387', '388.0', '[]', 'tracking']\nUnexpected format in submission file row: ['388', '389.0', '[]', 'tracking']\nUnexpected format in submission file row: ['389', '390.0', '[]', 'tracking']\nUnexpected format in submission file row: ['390', '391.0', '[]', 'tracking']\nUnexpected format in submission file row: ['391', '392.0', '[]', 'tracking']\nUnexpected format in submission file row: ['392', '393.0', '[]', 'tracking']\nUnexpected format in submission file row: ['393', '394.0', '[]', 'tracking']\nUnexpected format in submission file row: ['394', '395.0', '[]', 'tracking']\nUnexpected format in submission file row: ['395', '396.0', '[]', 'tracking']\nUnexpected format in submission file row: ['396', '397.0', '[]', 'tracking']\nUnexpected format in submission file row: ['397', '398.0', '[]', 'tracking']\nUnexpected format in submission file row: ['398', '399.0', '[]', 'tracking']\nUnexpected format in submission file row: ['399', '400.0', '[]', 'tracking']\nUnexpected format in submission file row: ['400', '401.0', '[]', 'tracking']\nUnexpected format in submission file row: ['401', '402.0', '[]', 'tracking']\nUnexpected format in submission file row: ['402', '403.0', '[]', 'tracking']\nUnexpected format in submission file row: ['403', '404.0', '[]', 'tracking']\nUnexpected format in submission file row: ['404', '405.0', '[]', 'tracking']\nUnexpected format in submission file row: ['405', '406.0', '[]', 'tracking']\nUnexpected format in submission file row: ['406', '407.0', '[]', 'tracking']\nUnexpected format in submission file row: ['407', '408.0', '[]', 'tracking']\nUnexpected format in submission file row: ['408', '409.0', '[]', 'tracking']\nUnexpected format in submission file row: ['409', '410.0', '[]', 'tracking']\nUnexpected format in submission file row: ['410', '411.0', '[]', 'tracking']\nUnexpected format in submission file row: ['411', '412.0', '[]', 'tracking']\nUnexpected format in submission file row: ['412', '413.0', '[]', 'tracking']\nUnexpected format in submission file row: ['413', '414.0', '[]', 'tracking']\nUnexpected format in submission file row: ['414', '415.0', '[]', 'tracking']\nUnexpected format in submission file row: ['415', '416.0', '[]', 'tracking']\nUnexpected format in submission file row: ['416', '417.0', '[]', 'tracking']\nUnexpected format in submission file row: ['417', '418.0', '[]', 'tracking']\nUnexpected format in submission file row: ['418', '419.0', '[]', 'tracking']\nUnexpected format in submission file row: ['419', '420.0', '[]', 'tracking']\nUnexpected format in submission file row: ['420', '421.0', '[]', 'tracking']\nUnexpected format in submission file row: ['421', '422.0', '[]', 'tracking']\nUnexpected format in submission file row: ['422', '423.0', '[]', 'tracking']\nUnexpected format in submission file row: ['423', '424.0', '[]', 'tracking']\nUnexpected format in submission file row: ['424', '425.0', '[]', 'tracking']\nUnexpected format in submission file row: ['425', '426.0', '[]', 'tracking']\nUnexpected format in submission file row: ['426', '427.0', '[]', 'tracking']\nUnexpected format in submission file row: ['427', '428.0', '[]', 'tracking']\nUnexpected format in submission file row: ['428', '429.0', '[]', 'tracking']\nLoaded 4734 image filenames from submission file.\n","output_type":"stream"},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/insightface/utils/transform.py:68: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  P = np.linalg.lstsq(X_homo, Y)[0].T # Affine matrix. 3 x 4\n","output_type":"stream"},{"name":"stdout","text":"No face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/test/4233.jpg\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/test/4564.jpg\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/test/5205.jpg\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/test/6597.jpg\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/test/10670.jpg\nNo face detected in /kaggle/input/surveillance-for-retail-stores/face_identification/face_identification/test/9743.jpg\nGenerated 4734 predictions.\nPredictions saved to /kaggle/working/predictions2.csv\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"# Tracker","metadata":{"_uuid":"08e056aa-a5bd-4798-aa0a-739e1e8e1992","_cell_guid":"b3c9f261-f568-48e4-aec9-3ca41c595a96","trusted":true,"collapsed":false,"jupyter":{"outputs_hidden":false}}},{"cell_type":"code","source":"import pandas as pd\n\n# Load both CSV files\ndf1 = pd.read_csv(\"/kaggle/input/tracking/submission.csv\")\ndf2 = pd.read_csv(\"/kaggle/working/predictions2.csv\")\n\n# Concatenate them\ndf_combined = pd.concat([df1, df2], ignore_index=False)\n\n# Save the merged CSV\ndf_combined.to_csv(\"/kaggle/working/bestsubmission.csv\", index=False)\n\nprint(f\"Merged CSV saved as submission.csv\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-23T22:32:18.521105Z","iopub.execute_input":"2025-03-23T22:32:18.521474Z","iopub.status.idle":"2025-03-23T22:32:18.632061Z","shell.execute_reply.started":"2025-03-23T22:32:18.521446Z","shell.execute_reply":"2025-03-23T22:32:18.631074Z"}},"outputs":[{"name":"stdout","text":"Merged CSV saved as submission.csv\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}