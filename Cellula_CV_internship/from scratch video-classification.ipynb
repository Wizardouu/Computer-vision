{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4006,"sourceType":"datasetVersion","datasetId":2386},{"sourceId":9455528,"sourceType":"datasetVersion","datasetId":5747912},{"sourceId":9457777,"sourceType":"datasetVersion","datasetId":5749543},{"sourceId":9457786,"sourceType":"datasetVersion","datasetId":5749550}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-22T17:57:56.450942Z","iopub.status.idle":"2024-09-22T17:57:56.451408Z","shell.execute_reply.started":"2024-09-22T17:57:56.451176Z","shell.execute_reply":"2024-09-22T17:57:56.451197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport os\nimport keras\n\ndataset_path = os.listdir('/kaggle/input/shop-dataset/Shop DataSet')\n\nlabel_types = os.listdir('/kaggle/input/shop-dataset/Shop DataSet')\nprint (label_types)  ","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:53:05.465125Z","iopub.execute_input":"2024-09-23T09:53:05.465584Z","iopub.status.idle":"2024-09-23T09:53:20.237592Z","shell.execute_reply.started":"2024-09-23T09:53:05.465536Z","shell.execute_reply":"2024-09-23T09:53:20.236175Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"['non shop lifters', 'shop lifters']\n","output_type":"stream"}]},{"cell_type":"code","source":"rooms = []\n\nfor item in dataset_path:\n # Get all the file names\n all_rooms = os.listdir('/kaggle/input/shop-dataset/Shop DataSet' + '/' +item)\n\n # Add them to the list\n for room in all_rooms:\n    rooms.append((item, str('/kaggle/input/shop-dataset/Shop DataSet' + '/' +item) + '/' + room))\n    \n# Build a dataframe        \ndataSet_df = pd.DataFrame(data=rooms, columns=['tag', 'video_name'])\nprint(dataSet_df.head())\nprint(dataSet_df.tail())","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:53:20.239665Z","iopub.execute_input":"2024-09-23T09:53:20.240353Z","iopub.status.idle":"2024-09-23T09:53:20.407207Z","shell.execute_reply.started":"2024-09-23T09:53:20.240307Z","shell.execute_reply":"2024-09-23T09:53:20.405767Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"                tag                                         video_name\n0  non shop lifters  /kaggle/input/shop-dataset/Shop DataSet/non sh...\n1  non shop lifters  /kaggle/input/shop-dataset/Shop DataSet/non sh...\n2  non shop lifters  /kaggle/input/shop-dataset/Shop DataSet/non sh...\n3  non shop lifters  /kaggle/input/shop-dataset/Shop DataSet/non sh...\n4  non shop lifters  /kaggle/input/shop-dataset/Shop DataSet/non sh...\n              tag                                         video_name\n850  shop lifters  /kaggle/input/shop-dataset/Shop DataSet/shop l...\n851  shop lifters  /kaggle/input/shop-dataset/Shop DataSet/shop l...\n852  shop lifters  /kaggle/input/shop-dataset/Shop DataSet/shop l...\n853  shop lifters  /kaggle/input/shop-dataset/Shop DataSet/shop l...\n854  shop lifters  /kaggle/input/shop-dataset/Shop DataSet/shop l...\n","output_type":"stream"}]},{"cell_type":"code","source":"df = dataSet_df.loc[:,['video_name','tag']]\ndf\ndf.to_csv('dataSet.csv')","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:53:20.408891Z","iopub.execute_input":"2024-09-23T09:53:20.409393Z","iopub.status.idle":"2024-09-23T09:53:20.433308Z","shell.execute_reply.started":"2024-09-23T09:53:20.409335Z","shell.execute_reply":"2024-09-23T09:53:20.431928Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow import keras\n\n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport imageio\nimport cv2\nimport os","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:53:20.436625Z","iopub.execute_input":"2024-09-23T09:53:20.437180Z","iopub.status.idle":"2024-09-23T09:53:20.760362Z","shell.execute_reply.started":"2024-09-23T09:53:20.437121Z","shell.execute_reply":"2024-09-23T09:53:20.758983Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n\n\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n    except RuntimeError as e:\n        print(e)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:53:20.761829Z","iopub.execute_input":"2024-09-23T09:53:20.762239Z","iopub.status.idle":"2024-09-23T09:53:20.773408Z","shell.execute_reply.started":"2024-09-23T09:53:20.762194Z","shell.execute_reply":"2024-09-23T09:53:20.771973Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Num GPUs Available:  0\n","output_type":"stream"}]},{"cell_type":"code","source":"dataSet_df = pd.read_csv(\"dataSet.csv\")\n\n\nprint(f\"Total videos in dataSet: {len(dataSet_df)}\")\n\n\n\ndataSet_df.sample(10)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:53:20.775277Z","iopub.execute_input":"2024-09-23T09:53:20.775702Z","iopub.status.idle":"2024-09-23T09:53:20.839937Z","shell.execute_reply.started":"2024-09-23T09:53:20.775658Z","shell.execute_reply":"2024-09-23T09:53:20.838824Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Total videos in dataSet: 855\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"     Unnamed: 0                                         video_name  \\\n822         822  /kaggle/input/shop-dataset/Shop DataSet/shop l...   \n301         301  /kaggle/input/shop-dataset/Shop DataSet/non sh...   \n852         852  /kaggle/input/shop-dataset/Shop DataSet/shop l...   \n277         277  /kaggle/input/shop-dataset/Shop DataSet/non sh...   \n569         569  /kaggle/input/shop-dataset/Shop DataSet/shop l...   \n714         714  /kaggle/input/shop-dataset/Shop DataSet/shop l...   \n451         451  /kaggle/input/shop-dataset/Shop DataSet/non sh...   \n679         679  /kaggle/input/shop-dataset/Shop DataSet/shop l...   \n811         811  /kaggle/input/shop-dataset/Shop DataSet/shop l...   \n566         566  /kaggle/input/shop-dataset/Shop DataSet/shop l...   \n\n                  tag  \n822      shop lifters  \n301  non shop lifters  \n852      shop lifters  \n277  non shop lifters  \n569      shop lifters  \n714      shop lifters  \n451  non shop lifters  \n679      shop lifters  \n811      shop lifters  \n566      shop lifters  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>video_name</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>822</th>\n      <td>822</td>\n      <td>/kaggle/input/shop-dataset/Shop DataSet/shop l...</td>\n      <td>shop lifters</td>\n    </tr>\n    <tr>\n      <th>301</th>\n      <td>301</td>\n      <td>/kaggle/input/shop-dataset/Shop DataSet/non sh...</td>\n      <td>non shop lifters</td>\n    </tr>\n    <tr>\n      <th>852</th>\n      <td>852</td>\n      <td>/kaggle/input/shop-dataset/Shop DataSet/shop l...</td>\n      <td>shop lifters</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>277</td>\n      <td>/kaggle/input/shop-dataset/Shop DataSet/non sh...</td>\n      <td>non shop lifters</td>\n    </tr>\n    <tr>\n      <th>569</th>\n      <td>569</td>\n      <td>/kaggle/input/shop-dataset/Shop DataSet/shop l...</td>\n      <td>shop lifters</td>\n    </tr>\n    <tr>\n      <th>714</th>\n      <td>714</td>\n      <td>/kaggle/input/shop-dataset/Shop DataSet/shop l...</td>\n      <td>shop lifters</td>\n    </tr>\n    <tr>\n      <th>451</th>\n      <td>451</td>\n      <td>/kaggle/input/shop-dataset/Shop DataSet/non sh...</td>\n      <td>non shop lifters</td>\n    </tr>\n    <tr>\n      <th>679</th>\n      <td>679</td>\n      <td>/kaggle/input/shop-dataset/Shop DataSet/shop l...</td>\n      <td>shop lifters</td>\n    </tr>\n    <tr>\n      <th>811</th>\n      <td>811</td>\n      <td>/kaggle/input/shop-dataset/Shop DataSet/shop l...</td>\n      <td>shop lifters</td>\n    </tr>\n    <tr>\n      <th>566</th>\n      <td>566</td>\n      <td>/kaggle/input/shop-dataset/Shop DataSet/shop l...</td>\n      <td>shop lifters</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# The following two methods are taken from this tutorial:\n# https://www.tensorflow.org/hub/tutorials/action_recognition_with_tf_hub\nIMG_SIZE = 224\n\n\ndef crop_center_square(frame):\n    y, x = frame.shape[0:2]\n    min_dim = min(y, x)\n    start_x = (x // 2) - (min_dim // 2)\n    start_y = (y // 2) - (min_dim // 2)\n    return frame[start_y : start_y + min_dim, start_x : start_x + min_dim]","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:53:20.841500Z","iopub.execute_input":"2024-09-23T09:53:20.841891Z","iopub.status.idle":"2024-09-23T09:53:20.849041Z","shell.execute_reply.started":"2024-09-23T09:53:20.841848Z","shell.execute_reply":"2024-09-23T09:53:20.847645Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import keras\n# Load video frames with batching\ndef load_video(path, max_frames=0, resize=(IMG_SIZE, IMG_SIZE)):\n    cap = cv2.VideoCapture(path)\n    frames = []\n    try:\n        while True:\n            ret, frame = cap.read()\n            if not ret:\n                break\n            frame = crop_center_square(frame)\n            frame = cv2.resize(frame, resize)\n            frame = frame[:, :, [2, 1, 0]]  # Convert BGR to RGB\n            frames.append(frame)\n\n            if max_frames > 0 and len(frames) == max_frames:\n                break\n    finally:\n        cap.release()\n    \n    return np.array(frames)\n\n# Build feature extractor using InceptionV3\ndef build_feature_extractor():\n    feature_extractor = keras.applications.InceptionV3(\n        weights=\"/kaggle/input/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\",\n        include_top=False,\n        pooling=\"avg\",\n        input_shape=(IMG_SIZE, IMG_SIZE, 3),\n    )\n    \n    preprocess_input = keras.applications.inception_v3.preprocess_input\n\n    inputs = keras.Input((IMG_SIZE, IMG_SIZE, 3))\n    preprocessed = preprocess_input(inputs)\n\n    outputs = feature_extractor(preprocessed)\n    \n    return keras.Model(inputs, outputs, name=\"feature_extractor\")\n\n# Create the feature extractor\nfeature_extractor = build_feature_extractor()\n\n# Function to extract features in batches\ndef extract_features_from_video(video_path, batch_size=32, max_frames=0):\n    frames = load_video(video_path, max_frames=max_frames)\n    features = []\n    \n    # Process frames in batches\n    for i in range(0, len(frames), batch_size):\n        batch = frames[i:i + batch_size]\n        batch_features = feature_extractor.predict(batch)\n        features.append(batch_features)\n\n    return np.concatenate(features, axis=0)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:53:20.851003Z","iopub.execute_input":"2024-09-23T09:53:20.851559Z","iopub.status.idle":"2024-09-23T09:53:25.199962Z","shell.execute_reply.started":"2024-09-23T09:53:20.851501Z","shell.execute_reply":"2024-09-23T09:53:25.198700Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"label_processor = keras.layers.StringLookup(num_oov_indices=0, vocabulary=np.unique(dataSet_df[\"tag\"]))\nprint(label_processor.get_vocabulary())\n\nlabels = dataSet_df[\"tag\"].values\n# Assuming 'tag' is the correct column name\nlabels = label_processor(dataSet_df[\"tag\"].values).numpy()\n\nlabels","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:53:25.201889Z","iopub.execute_input":"2024-09-23T09:53:25.202470Z","iopub.status.idle":"2024-09-23T09:53:25.253975Z","shell.execute_reply.started":"2024-09-23T09:53:25.202405Z","shell.execute_reply":"2024-09-23T09:53:25.252577Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"['non shop lifters', 'shop lifters']\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n       0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"},"metadata":{}}]},{"cell_type":"code","source":"#Define hyperparameters\n\nIMG_SIZE = 224\nBATCH_SIZE = 64\nEPOCHS = 100\n\nMAX_SEQ_LENGTH = 20\nNUM_FEATURES = 2048","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:53:25.257433Z","iopub.execute_input":"2024-09-23T09:53:25.258003Z","iopub.status.idle":"2024-09-23T09:53:25.315871Z","shell.execute_reply.started":"2024-09-23T09:53:25.257955Z","shell.execute_reply":"2024-09-23T09:53:25.314140Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def prepare_all_videos(df, root_dir, batch_size=32):\n    num_samples = len(df)\n    video_paths = df[\"video_name\"].values.tolist()\n\n    # Take all class labels from train_df column named 'tag' and store in labels\n    labels = df[\"tag\"].values\n\n    # Convert class labels to label encoding\n    labels = label_processor(labels[..., None]).numpy()\n\n    # `frame_masks` and `frame_features` are what we will feed to our sequence model.\n    frame_masks = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH), dtype=\"bool\")  # (num_samples, MAX_SEQ_LENGTH)\n    frame_features = np.zeros(shape=(num_samples, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")  # (num_samples, MAX_SEQ_LENGTH, NUM_FEATURES)\n\n    # For each video.\n    for idx, path in enumerate(video_paths):\n        # Gather all its frames\n        frames = load_video(os.path.join(root_dir, path))\n        print(len(frames))\n        video_length = frames.shape[0]\n\n        # Initialize a mask for the current video\n        length = min(MAX_SEQ_LENGTH, video_length)\n        frame_masks[idx, :length] = 1  # Mark the valid frames in the mask\n\n        # Extract features in batches\n        for start in range(0, video_length, batch_size):\n            end = min(start + batch_size, video_length)\n            batch = frames[start:end]\n\n            # Make predictions for the current batch\n            batch_features = feature_extractor.predict(batch)\n\n            # Assign features to the corresponding positions\n            for j in range(len(batch_features)):\n                if start + j < MAX_SEQ_LENGTH:\n                    frame_features[idx, start + j, :] = batch_features[j]\n\n    return (frame_features, frame_masks), labels\n\n# Example usage\ntrain_data, train_labels = prepare_all_videos(dataSet_df, \"train\")\n\nprint(f\"Frame features in train set: {train_data[0].shape}\")\nprint(f\"Frame masks in train set: {train_data[1].shape}\")\nprint(f\"Train labels in train set: {train_labels.shape}\")","metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2024-09-23T09:53:25.317928Z","iopub.execute_input":"2024-09-23T09:53:25.318449Z","iopub.status.idle":"2024-09-23T09:56:46.753994Z","shell.execute_reply.started":"2024-09-23T09:53:25.318388Z","shell.execute_reply":"2024-09-23T09:56:46.752167Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"350\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n275\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n425\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n300\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 682ms/step\n325\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 308ms/step\n425\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n375\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n250\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n375\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n575\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n","output_type":"stream"},{"name":"stderr","text":"\nKeyboardInterrupt\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import pickle\n\nwith open('labels.pkl', 'wb') as file:\n    pickle.dump(train_labels, file)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:56:52.821787Z","iopub.execute_input":"2024-09-23T09:56:52.822283Z","iopub.status.idle":"2024-09-23T09:56:53.453369Z","shell.execute_reply.started":"2024-09-23T09:56:52.822235Z","shell.execute_reply":"2024-09-23T09:56:53.451583Z"},"trusted":true},"execution_count":12,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m----> 4\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mtrain_labels\u001b[49m, file)\n","\u001b[0;31mNameError\u001b[0m: name 'train_labels' is not defined"],"ename":"NameError","evalue":"name 'train_labels' is not defined","output_type":"error"}]},{"cell_type":"code","source":"import pickle\n# Load from a file\nwith open('/kaggle/input/train-data/data.pkl', 'rb') as file:\n    data = pickle.load(file)\n\nprint(len(data[0]))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:57:09.727767Z","iopub.execute_input":"2024-09-23T09:57:09.728239Z","iopub.status.idle":"2024-09-23T09:57:10.858282Z","shell.execute_reply.started":"2024-09-23T09:57:09.728194Z","shell.execute_reply":"2024-09-23T09:57:10.856917Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"855\n","output_type":"stream"}]},{"cell_type":"code","source":"with open('/kaggle/input/train-labels/labels.pkl', 'rb') as file:\n    labels = pickle.load(file)\n\nprint(len(labels))","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:56:53.694683Z","iopub.execute_input":"2024-09-23T09:56:53.695148Z","iopub.status.idle":"2024-09-23T09:56:53.707229Z","shell.execute_reply.started":"2024-09-23T09:56:53.695094Z","shell.execute_reply":"2024-09-23T09:56:53.705951Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"855\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Extract frame features, frame masks, and labels\nframe_features, frame_masks = data  # train_data[0] and train_data[1]\nlabels = labels\n\n# Split the data into training and test sets\n(\n    X_train_features, X_test_features, \n    X_train_masks, X_test_masks, \n    y_train, y_test\n) = train_test_split(frame_features, frame_masks, labels, test_size=0.2, random_state=42)\n\n# Now you have split the data:\nprint(f\"Training frame features shape: {X_train_features.shape}\")\nprint(f\"Test frame features shape: {X_test_features.shape}\")\nprint(f\"Training frame masks shape: {X_train_masks.shape}\")\nprint(f\"Test frame masks shape: {X_test_masks.shape}\")\nprint(f\"Training labels shape: {y_train.shape}\")\nprint(f\"Test labels shape: {y_test.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T09:57:13.666458Z","iopub.execute_input":"2024-09-23T09:57:13.667486Z","iopub.status.idle":"2024-09-23T09:57:13.732300Z","shell.execute_reply.started":"2024-09-23T09:57:13.667436Z","shell.execute_reply":"2024-09-23T09:57:13.731001Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Training frame features shape: (684, 20, 2048)\nTest frame features shape: (171, 20, 2048)\nTraining frame masks shape: (684, 20)\nTest frame masks shape: (171, 20)\nTraining labels shape: (684, 1)\nTest labels shape: (171, 1)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Utility for our sequence model.\ndef get_sequence_model():\n    class_vocab = label_processor.get_vocabulary()\n\n    frame_features_input = keras.Input((MAX_SEQ_LENGTH, NUM_FEATURES))\n    mask_input = keras.Input((MAX_SEQ_LENGTH,), dtype=\"bool\")\n\n    # Refer to the following tutorial to understand the significance of using `mask`:\n    # https://keras.io/api/layers/recurrent_layers/gru/\n    x = keras.layers.GRU(16, return_sequences=True)(\n        frame_features_input, mask=mask_input\n    )\n    x = keras.layers.GRU(8)(x)\n    x = keras.layers.Dropout(0.4)(x)\n    x = keras.layers.Dense(8, activation=\"relu\")(x)\n    output = keras.layers.Dense(len(class_vocab), activation=\"softmax\")(x)\n\n    rnn_model = keras.Model([frame_features_input, mask_input], output)\n\n    rnn_model.compile(\n        loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]\n    )\n    return rnn_model\n\ndef run_experiment():\n    filepath = \"/tmp/video_classifier.weights.h5\"\n    checkpoint = keras.callbacks.ModelCheckpoint(\n        filepath, save_weights_only=True, save_best_only=True, verbose=1\n    )\n\n    seq_model = get_sequence_model()\n    history = seq_model.fit(\n        [X_train_features, X_train_masks],\n        y_train,\n        validation_split=0.2,\n        epochs=EPOCHS,\n        callbacks=[checkpoint],\n    )\n\n    seq_model.load_weights(filepath)\n    _, accuracy = seq_model.evaluate([X_test_features, X_test_masks], y_test)\n    print(f\"Test accuracy: {round(accuracy * 100, 2)}%\")\n\n    return history, seq_model\n_, sequence_model = run_experiment()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T10:09:38.017959Z","iopub.execute_input":"2024-09-23T10:09:38.018480Z","iopub.status.idle":"2024-09-23T10:10:42.869727Z","shell.execute_reply.started":"2024-09-23T10:09:38.018423Z","shell.execute_reply":"2024-09-23T10:10:42.868332Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5251 - loss: 0.7336\nEpoch 1: val_loss improved from inf to 0.61626, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.5311 - loss: 0.7273 - val_accuracy: 0.6788 - val_loss: 0.6163\nEpoch 2/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6409 - loss: 0.6408\nEpoch 2: val_loss improved from 0.61626 to 0.58348, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6379 - loss: 0.6418 - val_accuracy: 0.6788 - val_loss: 0.5835\nEpoch 3/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6961 - loss: 0.6073\nEpoch 3: val_loss improved from 0.58348 to 0.52183, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.6967 - loss: 0.6069 - val_accuracy: 0.8029 - val_loss: 0.5218\nEpoch 4/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7773 - loss: 0.5596\nEpoch 4: val_loss improved from 0.52183 to 0.48118, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7784 - loss: 0.5586 - val_accuracy: 0.8321 - val_loss: 0.4812\nEpoch 5/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.7398 - loss: 0.5522\nEpoch 5: val_loss improved from 0.48118 to 0.43374, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.7450 - loss: 0.5493 - val_accuracy: 0.8978 - val_loss: 0.4337\nEpoch 6/100\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8651 - loss: 0.4786\nEpoch 6: val_loss improved from 0.43374 to 0.36661, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8650 - loss: 0.4782 - val_accuracy: 0.9489 - val_loss: 0.3666\nEpoch 7/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8680 - loss: 0.4538\nEpoch 7: val_loss improved from 0.36661 to 0.34135, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8662 - loss: 0.4541 - val_accuracy: 0.8978 - val_loss: 0.3413\nEpoch 8/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8874 - loss: 0.3896\nEpoch 8: val_loss did not improve from 0.34135\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8885 - loss: 0.3878 - val_accuracy: 0.8759 - val_loss: 0.3513\nEpoch 9/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8858 - loss: 0.3607\nEpoch 9: val_loss did not improve from 0.34135\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8861 - loss: 0.3601 - val_accuracy: 0.8102 - val_loss: 0.4216\nEpoch 10/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8526 - loss: 0.3720\nEpoch 10: val_loss improved from 0.34135 to 0.19680, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8591 - loss: 0.3635 - val_accuracy: 0.9708 - val_loss: 0.1968\nEpoch 11/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9744 - loss: 0.1950\nEpoch 11: val_loss improved from 0.19680 to 0.18147, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9746 - loss: 0.1944 - val_accuracy: 0.9489 - val_loss: 0.1815\nEpoch 12/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9662 - loss: 0.1837\nEpoch 12: val_loss did not improve from 0.18147\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9663 - loss: 0.1824 - val_accuracy: 0.9562 - val_loss: 0.1826\nEpoch 13/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9592 - loss: 0.1546\nEpoch 13: val_loss improved from 0.18147 to 0.10879, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9604 - loss: 0.1523 - val_accuracy: 0.9781 - val_loss: 0.1088\nEpoch 14/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9806 - loss: 0.1160\nEpoch 14: val_loss did not improve from 0.10879\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9788 - loss: 0.1194 - val_accuracy: 0.9708 - val_loss: 0.1301\nEpoch 15/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9695 - loss: 0.1531\nEpoch 15: val_loss did not improve from 0.10879\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9667 - loss: 0.1600 - val_accuracy: 0.9635 - val_loss: 0.1113\nEpoch 16/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9566 - loss: 0.1691\nEpoch 16: val_loss improved from 0.10879 to 0.10390, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9533 - loss: 0.1767 - val_accuracy: 0.9708 - val_loss: 0.1039\nEpoch 17/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9801 - loss: 0.1055\nEpoch 17: val_loss did not improve from 0.10390\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9789 - loss: 0.1071 - val_accuracy: 0.9781 - val_loss: 0.1039\nEpoch 18/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9246 - loss: 0.2334\nEpoch 18: val_loss improved from 0.10390 to 0.09905, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9273 - loss: 0.2264 - val_accuracy: 0.9708 - val_loss: 0.0991\nEpoch 19/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9892 - loss: 0.0766\nEpoch 19: val_loss improved from 0.09905 to 0.08931, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9882 - loss: 0.0775 - val_accuracy: 0.9781 - val_loss: 0.0893\nEpoch 20/100\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9812 - loss: 0.0705\nEpoch 20: val_loss did not improve from 0.08931\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9807 - loss: 0.0723 - val_accuracy: 0.9124 - val_loss: 0.2534\nEpoch 21/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9652 - loss: 0.1431\nEpoch 21: val_loss did not improve from 0.08931\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9666 - loss: 0.1382 - val_accuracy: 0.9708 - val_loss: 0.0946\nEpoch 22/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9762 - loss: 0.0682\nEpoch 22: val_loss improved from 0.08931 to 0.08140, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9754 - loss: 0.0712 - val_accuracy: 0.9781 - val_loss: 0.0814\nEpoch 23/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9793 - loss: 0.0938\nEpoch 23: val_loss did not improve from 0.08140\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9787 - loss: 0.0951 - val_accuracy: 0.9708 - val_loss: 0.0887\nEpoch 24/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9859 - loss: 0.0789\nEpoch 24: val_loss did not improve from 0.08140\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9854 - loss: 0.0793 - val_accuracy: 0.9489 - val_loss: 0.1798\nEpoch 25/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9818 - loss: 0.0852\nEpoch 25: val_loss did not improve from 0.08140\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9818 - loss: 0.0838 - val_accuracy: 0.9781 - val_loss: 0.1023\nEpoch 26/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9865 - loss: 0.0722\nEpoch 26: val_loss improved from 0.08140 to 0.07849, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9864 - loss: 0.0711 - val_accuracy: 0.9854 - val_loss: 0.0785\nEpoch 27/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9876 - loss: 0.0662\nEpoch 27: val_loss did not improve from 0.07849\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9860 - loss: 0.0705 - val_accuracy: 0.8248 - val_loss: 0.6016\nEpoch 28/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9092 - loss: 0.2509\nEpoch 28: val_loss did not improve from 0.07849\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9099 - loss: 0.2467 - val_accuracy: 0.9489 - val_loss: 0.1289\nEpoch 29/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9758 - loss: 0.1111\nEpoch 29: val_loss did not improve from 0.07849\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9759 - loss: 0.1102 - val_accuracy: 0.9124 - val_loss: 0.2761\nEpoch 30/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9576 - loss: 0.1167\nEpoch 30: val_loss did not improve from 0.07849\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9588 - loss: 0.1148 - val_accuracy: 0.9416 - val_loss: 0.1822\nEpoch 31/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.8739 - loss: 0.3752\nEpoch 31: val_loss improved from 0.07849 to 0.05718, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8759 - loss: 0.3690 - val_accuracy: 0.9781 - val_loss: 0.0572\nEpoch 32/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9677 - loss: 0.1067\nEpoch 32: val_loss did not improve from 0.05718\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9676 - loss: 0.1064 - val_accuracy: 0.9343 - val_loss: 0.1716\nEpoch 33/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9546 - loss: 0.1303\nEpoch 33: val_loss did not improve from 0.05718\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9567 - loss: 0.1269 - val_accuracy: 0.9708 - val_loss: 0.1069\nEpoch 34/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9892 - loss: 0.0797\nEpoch 34: val_loss did not improve from 0.05718\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9894 - loss: 0.0784 - val_accuracy: 0.9781 - val_loss: 0.0722\nEpoch 35/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9935 - loss: 0.0488\nEpoch 35: val_loss improved from 0.05718 to 0.04084, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.9936 - loss: 0.0491 - val_accuracy: 0.9781 - val_loss: 0.0408\nEpoch 36/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9902 - loss: 0.0333\nEpoch 36: val_loss did not improve from 0.04084\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9905 - loss: 0.0335 - val_accuracy: 0.9854 - val_loss: 0.0457\nEpoch 37/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9882 - loss: 0.0749\nEpoch 37: val_loss did not improve from 0.04084\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9889 - loss: 0.0715 - val_accuracy: 0.9854 - val_loss: 0.0483\nEpoch 38/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9892 - loss: 0.0492\nEpoch 38: val_loss did not improve from 0.04084\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9898 - loss: 0.0483 - val_accuracy: 0.9854 - val_loss: 0.0421\nEpoch 39/100\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9943 - loss: 0.0471\nEpoch 39: val_loss did not improve from 0.04084\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9942 - loss: 0.0470 - val_accuracy: 0.9854 - val_loss: 0.0490\nEpoch 40/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9937 - loss: 0.0264\nEpoch 40: val_loss did not improve from 0.04084\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9934 - loss: 0.0275 - val_accuracy: 0.9270 - val_loss: 0.2795\nEpoch 41/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9507 - loss: 0.1831\nEpoch 41: val_loss did not improve from 0.04084\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 37ms/step - accuracy: 0.9518 - loss: 0.1782 - val_accuracy: 0.9708 - val_loss: 0.0553\nEpoch 42/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9918 - loss: 0.0590\nEpoch 42: val_loss did not improve from 0.04084\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9913 - loss: 0.0603 - val_accuracy: 0.9635 - val_loss: 0.1396\nEpoch 43/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9919 - loss: 0.0535\nEpoch 43: val_loss improved from 0.04084 to 0.03828, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 38ms/step - accuracy: 0.9920 - loss: 0.0524 - val_accuracy: 0.9781 - val_loss: 0.0383\nEpoch 44/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9961 - loss: 0.0315\nEpoch 44: val_loss did not improve from 0.03828\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9959 - loss: 0.0323 - val_accuracy: 0.9927 - val_loss: 0.0429\nEpoch 45/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9998 - loss: 0.0230\nEpoch 45: val_loss improved from 0.03828 to 0.03785, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9996 - loss: 0.0237 - val_accuracy: 0.9781 - val_loss: 0.0379\nEpoch 46/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9905 - loss: 0.0310\nEpoch 46: val_loss did not improve from 0.03785\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9904 - loss: 0.0322 - val_accuracy: 0.9562 - val_loss: 0.1695\nEpoch 47/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9901 - loss: 0.0361\nEpoch 47: val_loss did not improve from 0.03785\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9905 - loss: 0.0356 - val_accuracy: 0.9927 - val_loss: 0.0408\nEpoch 48/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9516 - loss: 0.1407\nEpoch 48: val_loss did not improve from 0.03785\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9482 - loss: 0.1499 - val_accuracy: 0.9854 - val_loss: 0.0912\nEpoch 49/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9722 - loss: 0.0926\nEpoch 49: val_loss did not improve from 0.03785\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9730 - loss: 0.0894 - val_accuracy: 0.9854 - val_loss: 0.0445\nEpoch 50/100\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9894 - loss: 0.0277\nEpoch 50: val_loss improved from 0.03785 to 0.02741, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9896 - loss: 0.0275 - val_accuracy: 0.9927 - val_loss: 0.0274\nEpoch 51/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0134\nEpoch 51: val_loss did not improve from 0.02741\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9998 - loss: 0.0137 - val_accuracy: 0.8686 - val_loss: 0.6052\nEpoch 52/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8271 - loss: 0.8943\nEpoch 52: val_loss did not improve from 0.02741\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.8278 - loss: 0.8693 - val_accuracy: 0.9270 - val_loss: 0.3431\nEpoch 53/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.7946 - loss: 0.3773\nEpoch 53: val_loss did not improve from 0.02741\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.7989 - loss: 0.3690 - val_accuracy: 0.9781 - val_loss: 0.0889\nEpoch 54/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9900 - loss: 0.0911\nEpoch 54: val_loss did not improve from 0.02741\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9898 - loss: 0.0901 - val_accuracy: 0.9781 - val_loss: 0.0531\nEpoch 55/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9994 - loss: 0.0503\nEpoch 55: val_loss did not improve from 0.02741\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9991 - loss: 0.0502 - val_accuracy: 0.9854 - val_loss: 0.0378\nEpoch 56/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9926 - loss: 0.0527\nEpoch 56: val_loss did not improve from 0.02741\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9928 - loss: 0.0515 - val_accuracy: 0.9854 - val_loss: 0.0306\nEpoch 57/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9991 - loss: 0.0402\nEpoch 57: val_loss did not improve from 0.02741\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9990 - loss: 0.0394 - val_accuracy: 0.9854 - val_loss: 0.0286\nEpoch 58/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9964 - loss: 0.0257\nEpoch 58: val_loss did not improve from 0.02741\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9964 - loss: 0.0259 - val_accuracy: 0.9708 - val_loss: 0.1045\nEpoch 59/100\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9889 - loss: 0.0411\nEpoch 59: val_loss did not improve from 0.02741\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9891 - loss: 0.0406 - val_accuracy: 0.9781 - val_loss: 0.0625\nEpoch 60/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0209\nEpoch 60: val_loss did not improve from 0.02741\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0209 - val_accuracy: 0.9781 - val_loss: 0.0333\nEpoch 61/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9999 - loss: 0.0178\nEpoch 61: val_loss improved from 0.02741 to 0.01776, saving model to /tmp/video_classifier.weights.h5\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9997 - loss: 0.0181 - val_accuracy: 0.9927 - val_loss: 0.0178\nEpoch 62/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9950 - loss: 0.0158\nEpoch 62: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9949 - loss: 0.0161 - val_accuracy: 0.9562 - val_loss: 0.1258\nEpoch 63/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9994 - loss: 0.0203\nEpoch 63: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9993 - loss: 0.0202 - val_accuracy: 0.9416 - val_loss: 0.1714\nEpoch 64/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9641 - loss: 0.0940\nEpoch 64: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9626 - loss: 0.0990 - val_accuracy: 0.9708 - val_loss: 0.1814\nEpoch 65/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9610 - loss: 0.1176\nEpoch 65: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.9606 - loss: 0.1189 - val_accuracy: 0.9489 - val_loss: 0.1289\nEpoch 66/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9752 - loss: 0.0546\nEpoch 66: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9765 - loss: 0.0521 - val_accuracy: 0.9927 - val_loss: 0.0411\nEpoch 67/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.9929 - loss: 0.0314\nEpoch 67: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9930 - loss: 0.0308 - val_accuracy: 0.9708 - val_loss: 0.0630\nEpoch 68/100\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0137\nEpoch 68: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9781 - val_loss: 0.0884\nEpoch 69/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0134\nEpoch 69: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.9927 - val_loss: 0.0365\nEpoch 70/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0100\nEpoch 70: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9781 - val_loss: 0.0467\nEpoch 71/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 1.0000 - loss: 0.0164\nEpoch 71: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.9854 - val_loss: 0.0422\nEpoch 72/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0115\nEpoch 72: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.9854 - val_loss: 0.0421\nEpoch 73/100\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9983 - loss: 0.0141\nEpoch 73: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9982 - loss: 0.0141 - val_accuracy: 0.9781 - val_loss: 0.0487\nEpoch 74/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9937 - loss: 0.0153\nEpoch 74: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9942 - loss: 0.0148 - val_accuracy: 0.9781 - val_loss: 0.0552\nEpoch 75/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9929 - loss: 0.0143\nEpoch 75: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9933 - loss: 0.0140 - val_accuracy: 0.9781 - val_loss: 0.0562\nEpoch 76/100\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0082\nEpoch 76: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 0.0082 - val_accuracy: 0.9854 - val_loss: 0.0421\nEpoch 77/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0095\nEpoch 77: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.9781 - val_loss: 0.0626\nEpoch 78/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9993 - loss: 0.0058\nEpoch 78: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0063 - val_accuracy: 0.9781 - val_loss: 0.0759\nEpoch 79/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 1.0000 - loss: 0.0071\nEpoch 79: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 1.0000 - loss: 0.0070 - val_accuracy: 0.9854 - val_loss: 0.0527\nEpoch 80/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0068\nEpoch 80: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9994 - loss: 0.0070 - val_accuracy: 0.9927 - val_loss: 0.0434\nEpoch 81/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9995 - loss: 0.0089\nEpoch 81: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9991 - loss: 0.0103 - val_accuracy: 0.6934 - val_loss: 1.6677\nEpoch 82/100\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.5211 - loss: 3.0067\nEpoch 82: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5171 - loss: 2.9837 - val_accuracy: 0.6788 - val_loss: 0.6301\nEpoch 83/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6071 - loss: 0.9025\nEpoch 83: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.6059 - loss: 0.9038 - val_accuracy: 0.6788 - val_loss: 0.6359\nEpoch 84/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5574 - loss: 0.7316\nEpoch 84: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5509 - loss: 0.7320 - val_accuracy: 0.6788 - val_loss: 0.6541\nEpoch 85/100\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5127 - loss: 0.7027\nEpoch 85: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5134 - loss: 0.7027 - val_accuracy: 0.6788 - val_loss: 0.6398\nEpoch 86/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.5504 - loss: 0.6983\nEpoch 86: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.5519 - loss: 0.6977 - val_accuracy: 0.6788 - val_loss: 0.6384\nEpoch 87/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5426 - loss: 0.6958\nEpoch 87: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.5438 - loss: 0.6941 - val_accuracy: 0.6788 - val_loss: 0.6389\nEpoch 88/100\n\u001b[1m16/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.5662 - loss: 0.6903\nEpoch 88: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.5663 - loss: 0.6899 - val_accuracy: 0.6788 - val_loss: 0.6365\nEpoch 89/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5483 - loss: 0.7064\nEpoch 89: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5510 - loss: 0.7038 - val_accuracy: 0.6788 - val_loss: 0.6353\nEpoch 90/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5807 - loss: 0.6860\nEpoch 90: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5819 - loss: 0.6854 - val_accuracy: 0.6788 - val_loss: 0.6337\nEpoch 91/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5614 - loss: 0.6794\nEpoch 91: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5616 - loss: 0.6791 - val_accuracy: 0.6788 - val_loss: 0.6423\nEpoch 92/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5810 - loss: 0.6878\nEpoch 92: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5810 - loss: 0.6883 - val_accuracy: 0.6788 - val_loss: 0.6327\nEpoch 93/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.5885 - loss: 0.6786\nEpoch 93: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 31ms/step - accuracy: 0.5888 - loss: 0.6783 - val_accuracy: 0.6788 - val_loss: 0.6432\nEpoch 94/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5707 - loss: 0.6866\nEpoch 94: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5711 - loss: 0.6861 - val_accuracy: 0.6788 - val_loss: 0.6477\nEpoch 95/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.5832 - loss: 0.6713\nEpoch 95: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.5822 - loss: 0.6720 - val_accuracy: 0.6788 - val_loss: 0.6405\nEpoch 96/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.6153 - loss: 0.6617\nEpoch 96: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.6127 - loss: 0.6626 - val_accuracy: 0.6788 - val_loss: 0.6361\nEpoch 97/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6045 - loss: 0.6812\nEpoch 97: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.6038 - loss: 0.6810 - val_accuracy: 0.6788 - val_loss: 0.6378\nEpoch 98/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.6240 - loss: 0.6634\nEpoch 98: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6214 - loss: 0.6645 - val_accuracy: 0.6788 - val_loss: 0.6409\nEpoch 99/100\n\u001b[1m17/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.6056 - loss: 0.6747\nEpoch 99: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.6042 - loss: 0.6756 - val_accuracy: 0.6788 - val_loss: 0.6460\nEpoch 100/100\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6139 - loss: 0.6807\nEpoch 100: val_loss did not improve from 0.01776\n\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.6136 - loss: 0.6809 - val_accuracy: 0.6788 - val_loss: 0.6405\n\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9923 - loss: 0.0240 \nTest accuracy: 98.83%\n","output_type":"stream"}]},{"cell_type":"code","source":"def extract_video_features(video_path, batch_size=32):\n    # Load the video and get its frames\n    frames = load_video(video_path)\n    video_length = frames.shape[0]\n\n    # Initialize frame masks and features for this single video\n    frame_masks = np.zeros(shape=(1, MAX_SEQ_LENGTH), dtype=\"bool\")\n    frame_features = np.zeros(shape=(1, MAX_SEQ_LENGTH, NUM_FEATURES), dtype=\"float32\")\n\n    # Initialize a mask for the current video (mark the valid frames in the mask)\n    length = min(MAX_SEQ_LENGTH, video_length)\n    frame_masks[0, :length] = 1\n\n    # Extract features in batches\n    for start in range(0, video_length, batch_size):\n        end = min(start + batch_size, video_length)\n        batch = frames[start:end]\n\n        # Extract features for the current batch using the feature extractor\n        batch_features = feature_extractor.predict(batch)\n\n        # Assign the features to the corresponding positions\n        for j in range(len(batch_features)):\n            if start + j < MAX_SEQ_LENGTH:\n                frame_features[0, start + j, :] = batch_features[j]\n\n    return frame_features, frame_masks\n\n# Function to predict the class for a new video\ndef predict_video_class(video_path):\n    # Extract features and masks for the video\n    video_features, video_masks = extract_video_features(video_path)\n\n    # Use the trained sequence model to predict the class\n    class_probs = sequence_model.predict([video_features, video_masks])\n    predicted_class_idx = np.argmax(class_probs, axis=1)[0]\n\n    # Convert the predicted index back to the class name\n    predicted_class_name = label_processor.get_vocabulary()[predicted_class_idx]\n\n    return predicted_class_name\n\n# Example usage\nvideo_path = \"/kaggle/input/shop-dataset/Shop DataSet/non shop lifters/shop_lifter_n_105.mp4\"\npredicted_class = predict_video_class(video_path)\nprint(f\"Predicted class for the video: {predicted_class}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T10:11:03.795937Z","iopub.execute_input":"2024-09-23T10:11:03.796879Z","iopub.status.idle":"2024-09-23T10:11:22.084923Z","shell.execute_reply.started":"2024-09-23T10:11:03.796821Z","shell.execute_reply":"2024-09-23T10:11:22.083756Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 434ms/step\nPredicted class for the video: non shop lifters\n","output_type":"stream"}]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Function to evaluate the model and print the confusion matrix and classification report\ndef evaluate_model(seq_model, X_test_features, X_test_masks, y_test):\n    # Make predictions on the test set\n    y_pred_prob = seq_model.predict([X_test_features, X_test_masks])\n    \n    # Convert predicted probabilities to class labels\n    y_pred = np.argmax(y_pred_prob, axis=1)\n    \n    # Confusion matrix\n    cm = confusion_matrix(y_test, y_pred)\n    \n    # Plot confusion matrix\n    plt.figure(figsize=(10, 7))\n    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_processor.get_vocabulary(), yticklabels=label_processor.get_vocabulary())\n    plt.xlabel('Predicted')\n    plt.ylabel('Actual')\n    plt.title('Confusion Matrix')\n    plt.show()\n\n    # Classification report\n    print(\"Classification Report:\\n\")\n    report = classification_report(y_test, y_pred, target_names=label_processor.get_vocabulary())\n    print(report)\n\n# Example usage\nevaluate_model(sequence_model, X_test_features, X_test_masks, y_test)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T10:11:27.485135Z","iopub.execute_input":"2024-09-23T10:11:27.485614Z","iopub.status.idle":"2024-09-23T10:11:28.372132Z","shell.execute_reply.started":"2024-09-23T10:11:27.485566Z","shell.execute_reply":"2024-09-23T10:11:28.370967Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step \n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x700 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"Classification Report:\n\n                  precision    recall  f1-score   support\n\nnon shop lifters       0.99      0.99      0.99       108\n    shop lifters       0.98      0.98      0.98        63\n\n        accuracy                           0.99       171\n       macro avg       0.99      0.99      0.99       171\n    weighted avg       0.99      0.99      0.99       171\n\n","output_type":"stream"}]}]}